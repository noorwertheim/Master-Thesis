{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timesfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtimesfm\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timesfm'"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoformerConfig, AutoformerModel\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from transformers import AutoformerConfig, AutoformerForPrediction\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timesfm\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n",
      "{'record_name': 'Hopper-2023_05_25_12_03_38-0000010090-0003-chan0', 'signal': array([[-1.70320951],\n",
      "       [-3.4187519 ],\n",
      "       [-2.48399421],\n",
      "       ...,\n",
      "       [ 0.73116871],\n",
      "       [ 0.4095313 ],\n",
      "       [ 0.95039407]]), 'fs': 20, 'preterm': 0}\n",
      "Number of instances with None in 'preterm': 144\n",
      "Remaining instances after deletion: 858\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(univariate_data_path, \"target_univariate_no_PCA.npy\")\n",
    "target_data = np.load(save_dir, allow_pickle=True)\n",
    "print(len(target_data))\n",
    "print(target_data[0])\n",
    "num_none_preterm = sum(1 for item in target_data if item['preterm'] is None)\n",
    "print(f\"Number of instances with None in 'preterm': {num_none_preterm}\")\n",
    "target_data = [item for item in target_data if item['preterm'] is not None]\n",
    "print(f\"Remaining instances after deletion: {len(target_data)}\")\n",
    "\n",
    "target_data = pd.DataFrame(target_data)\n",
    "print(type(target_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': Timestamp('2025-04-17 09:33:31.734054'), 'target': array([[-1.70320951],\n",
      "       [-3.4187519 ],\n",
      "       [-2.48399421],\n",
      "       ...,\n",
      "       [ 0.73116871],\n",
      "       [ 0.4095313 ],\n",
      "       [ 0.95039407]]), 'item_id': 'Hopper-2023_05_25_12_03_38-0000010090-0003-chan0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "formatted_data = [\n",
    "    {\n",
    "        \"start\": pd.Timestamp(datetime.now()),  # Replace with actual timestamp if you have it\n",
    "        \"target\": row[\"signal\"].astype(float),\n",
    "        \"item_id\": row[\"record_name\"]\n",
    "    }\n",
    "    for _, row in target_data.iterrows()\n",
    "]\n",
    "print(formatted_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 686 samples\n",
      "Validation: 86 samples\n",
      "Test: 86 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into 80% train and 20% temp (val + test)\n",
    "train_data, temp_data = train_test_split(\n",
    "    formatted_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Then split the 20% temp into 50% val, 50% test => 10% each\n",
    "val_data, test_data = train_test_split(\n",
    "    temp_data, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Validation: {len(val_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_model' from 'timesfm' (/home/nwertheim/Master-Thesis/timesfm-env/lib64/python3.11/site-packages/timesfm/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtimesfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimesFm\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtimesfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtimesfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m      6\u001b[39m tfm = load_model(\u001b[33m\"\u001b[39m\u001b[33mgoogle/timesfm-1.0-200m\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'load_model' from 'timesfm' (/home/nwertheim/Master-Thesis/timesfm-env/lib64/python3.11/site-packages/timesfm/__init__.py)"
     ]
    }
   ],
   "source": [
    "from timesfm import TimesFm\n",
    "from timesfm import load_model\n",
    "\n",
    "tfm = load_model(\"google/timesfm-1.0-200m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envnoor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
