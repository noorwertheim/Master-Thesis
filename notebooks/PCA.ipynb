{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path\n",
    "from scipy.signal import resample\n",
    "from preprocessing_modules import EHGRecord, trim_target, filter_target, z_normalize_target, check_normalize_target, remove_records, z_normalize_signals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'tpehgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained Variance for tpehgt_n001: 0.586030\n",
      "Retained Variance for tpehgt_n002: 0.574200\n",
      "Retained Variance for tpehgt_n003: 0.777624\n",
      "Retained Variance for tpehgt_n004: 0.759304\n",
      "Retained Variance for tpehgt_n005: 0.686037\n",
      "Retained Variance for tpehgt_p001: 0.557237\n",
      "Retained Variance for tpehgt_p002: 0.644650\n",
      "Retained Variance for tpehgt_p003: 0.481346\n",
      "Retained Variance for tpehgt_p004: 0.524668\n",
      "Retained Variance for tpehgt_p005: 0.585139\n",
      "Retained Variance for tpehgt_p006: 0.758221\n",
      "Retained Variance for tpehgt_p007: 0.551946\n",
      "Retained Variance for tpehgt_p008: 0.447605\n",
      "Retained Variance for tpehgt_p009: 0.474526\n",
      "Retained Variance for tpehgt_p010: 0.411020\n",
      "Retained Variance for tpehgt_p011: 0.649345\n",
      "Retained Variance for tpehgt_p012: 0.558731\n",
      "Retained Variance for tpehgt_p013: 0.535757\n",
      "Retained Variance for tpehgt_t001: 0.493252\n",
      "Retained Variance for tpehgt_t002: 0.508303\n",
      "Retained Variance for tpehgt_t003: 0.499541\n",
      "Retained Variance for tpehgt_t004: 0.608306\n",
      "Retained Variance for tpehgt_t005: 0.478783\n",
      "Retained Variance for tpehgt_t006: 0.493229\n",
      "Retained Variance for tpehgt_t007: 0.609603\n",
      "Retained Variance for tpehgt_t008: 0.578894\n",
      "Retained Variance for tpehgt_t009: 0.548202\n",
      "Retained Variance for tpehgt_t010: 0.608595\n",
      "Retained Variance for tpehgt_t011: 0.595704\n",
      "Retained Variance for tpehgt_t012: 0.772637\n",
      "Retained Variance for tpehgt_t013: 0.437426\n",
      "\n",
      "Average Retained Variance for tpehgt: 0.574060\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def univariate(dataset_name):\n",
    "    data_dir = os.path.join(processed_data_path, dataset_name + \"_preprocessed.npy\")\n",
    "    data = np.load(data_dir, allow_pickle=True)\n",
    "\n",
    "    # Define the path to save the new dataset\n",
    "    \n",
    "\n",
    "    # Initialize a list for storing modified entries\n",
    "    univariate_data = []\n",
    "    retained_variances = []  # List to store retained variance for each entry\n",
    "\n",
    "    for entry in data:\n",
    "        # Copy the entry to preserve metadata\n",
    "        new_entry = entry.copy()\n",
    "\n",
    "        # Extract the signal matrix (shape: (599999, 6))\n",
    "        signal_matrix = entry['signal']\n",
    "        \n",
    "        # Apply PCA to reduce from 6D to 1D\n",
    "        pca = PCA(n_components=1)\n",
    "        reduced_signal = pca.fit_transform(signal_matrix)  # Shape: (599999, 1)\n",
    "        \n",
    "        # Calculate retained variance\n",
    "        retained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "        retained_variances.append(retained_variance)\n",
    "\n",
    "        print(f\"Retained Variance for {entry['record_name']}: {retained_variance:.6f}\")\n",
    "        \n",
    "        # Flatten to (599999,) to retain time-series format\n",
    "        new_entry['signal'] = reduced_signal.flatten()\n",
    "\n",
    "        # Append modified entry to the new dataset\n",
    "        univariate_data.append(new_entry)\n",
    "\n",
    "    # Compute the average retained variance for the dataset\n",
    "    avg_retained_variance = np.mean(retained_variances)\n",
    "    print(f\"\\nAverage Retained Variance for {dataset_name}: {avg_retained_variance:.6f}\")\n",
    "\n",
    "    # Convert to a NumPy array and save\n",
    "    \n",
    "    return univariate_data\n",
    "\n",
    "univariate_data = univariate(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "32900 32900\n",
      "old signal lengt 32900\n",
      "new length 32900\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "32880 32880\n",
      "old signal lengt 32880\n",
      "new length 32880\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "32900 32900\n",
      "old signal lengt 32900\n",
      "new length 32900\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33060 33060\n",
      "old signal lengt 33060\n",
      "new length 33060\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "32800 32800\n",
      "old signal lengt 32800\n",
      "new length 32800\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33599 33599\n",
      "old signal lengt 33599\n",
      "new length 33599\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "óriginaloriginal_fs 20\n",
      "20 20\n",
      "33600 33600\n",
      "old signal lengt 33600\n",
      "new length 33600\n",
      "PCA transformation complete. Saved as '../data/univariate/tpehgt_univariate.npy'.\n",
      "32880\n",
      "32880\n",
      "{'record_name': 'tpehgt_n002', 'signal': array([[ 0.96902565],\n",
      "       [ 1.09890973],\n",
      "       [ 1.20649307],\n",
      "       ...,\n",
      "       [-3.25574938],\n",
      "       [-3.24965941],\n",
      "       [-3.24305109]]), 'metadata': {'fs': 20, 'sig_len': 35280, 'n_sig': 8, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'comments': ['Comments:', 'RecID\\ttpehgt_n002', 'RecType Non-pregnant', 'Gestation N/A', 'Rectime N/A', 'Age None', 'Parity None', 'Abortions None', 'Weight None', 'Placental_position N/A', 'Smoker None']}}\n"
     ]
    }
   ],
   "source": [
    "def downsample_target(univariate_data, target_fs=20):\n",
    "    \"\"\"\n",
    "    Downsamples all signals OF TARGET SET in univariate_data to the target frequency (default: 20Hz).\n",
    "    \n",
    "    Parameters:\n",
    "    - univariate_data (list of dicts): Each entry should have 'metadata' with 'fs' (sampling rate) and 'signal'.\n",
    "    - target_fs (int): The target sampling frequency (default is 20 Hz).\n",
    "    \n",
    "    Returns:\n",
    "    - downsampled_data (list of dicts): Same structure as input but with downsampled signals.\n",
    "    \"\"\"\n",
    "    downsampled_data = []\n",
    "    \n",
    "    for entry in univariate_data:\n",
    "        original_fs = entry['fs']\n",
    "        print('óriginaloriginal_fs', original_fs)\n",
    "        signal = entry['signal']\n",
    "        \n",
    "        # Compute the new length after downsampling\n",
    "        new_length = int(len(signal) * target_fs / original_fs)\n",
    "        print(target_fs, original_fs)\n",
    "        print(len(signal), new_length)\n",
    "        \n",
    "        # Resample the signal\n",
    "        downsampled_signal = resample(signal, new_length)\n",
    "        print('old signal lengt', len(signal))\n",
    "        print('new length', len(downsampled_signal))\n",
    "        # Store the downsampled signal with updated metadata\n",
    "        downsampled_entry = {\n",
    "            'fs': target_fs,\n",
    "            'signal': downsampled_signal,\n",
    "            'record_name': entry['record_name'],\n",
    "            'preterm': entry['preterm']\n",
    "        }\n",
    "        downsampled_data.append(downsampled_entry)\n",
    "    downsampled_data = z_normalize_target(downsampled_data)\n",
    "    save_dir = os.path.join(univariate_data_path, dataset + \"_univariate.npy\")\n",
    "    np.save(save_dir, np.array(downsampled_data, dtype=object))\n",
    "\n",
    "    print(f\"PCA transformation complete. Saved as '{save_dir}'.\")\n",
    "    \n",
    "    return downsampled_data\n",
    "\n",
    "def downsample_signal(univariate_data, target_fs=20):\n",
    "    \"\"\"\n",
    "    Downsamples all signals in univariate_data to the target frequency (default: 20Hz).\n",
    "    \n",
    "    Parameters:\n",
    "    - univariate_data (list of dicts): Each entry should have 'metadata' with 'fs' (sampling rate) and 'signal'.\n",
    "    - target_fs (int): The target sampling frequency (default is 20 Hz).\n",
    "    \n",
    "    Returns:\n",
    "    - downsampled_data (list of dicts): Same structure as input but with downsampled signals.\n",
    "    \"\"\"\n",
    "    downsampled_data = []\n",
    "    \n",
    "    for entry in univariate_data:\n",
    "        original_fs = entry['metadata']['fs']\n",
    "        print('óriginaloriginal_fs', original_fs)\n",
    "        signal = entry['signal']\n",
    "        \n",
    "        # Compute the new length after downsampling\n",
    "        new_length = int(len(signal) * target_fs / original_fs)\n",
    "        print(target_fs, original_fs)\n",
    "        print(len(signal), new_length)\n",
    "        \n",
    "        # Resample the signal\n",
    "        downsampled_signal = resample(signal, new_length)\n",
    "        print('old signal lengt', len(signal))\n",
    "        print('new length', len(downsampled_signal))\n",
    "        # Store the downsampled signal with updated metadata\n",
    "        downsampled_entry = {\n",
    "            'metadata': {**entry['metadata'], 'fs': target_fs},\n",
    "            'signal': downsampled_signal,\n",
    "            'record_name': entry['record_name']\n",
    "        }\n",
    "        downsampled_data.append(downsampled_entry)\n",
    "    \n",
    "    downsampled_data = z_normalize_signals(downsampled_data)\n",
    "    save_dir = os.path.join(univariate_data_path, dataset + \"_univariate.npy\")\n",
    "    np.save(save_dir, np.array(downsampled_data, dtype=object))\n",
    "\n",
    "    print(f\"PCA transformation complete. Saved as '{save_dir}'.\")\n",
    "    \n",
    "    return downsampled_data\n",
    "\n",
    "if dataset == 'target':\n",
    "    downsampled_data = downsample_target(univariate_data)\n",
    "else: \n",
    "    downsampled_data = downsample_signal(univariate_data)\n",
    "print(len(univariate_data[1]['signal']))\n",
    "print(len(downsampled_data[1]['signal']))\n",
    "\n",
    "# print(data[1])\n",
    "print(downsampled_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600\n",
      "{'record_name': 'ice001_l_1of1', 'signal': array([[-1.7358303 ],\n",
      "       [-0.30347557],\n",
      "       [-0.40749874],\n",
      "       ...,\n",
      "       [-3.09738299],\n",
      "       [-2.90981482],\n",
      "       [-3.22768386]]), 'metadata': {'fs': 20, 'sig_len': 100000, 'n_sig': 16, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'comments': ['Info:', 'ID:ice001', 'Record type:labour', 'Record number:1/1', 'Age(years):31', 'BMI before pregnancy:23.3', 'BMI at recording:27.6', 'Gravidity:3', 'Parity:2', 'Previous caesarean:No', 'Placental position:Fundus', 'Gestational age at recording(w/d):39/3', 'Gestational age at delivery:39/3', 'Mode of delivery:Vaginal', 'Synthetic oxytocin use in labour:No', 'Epidural during labour:No', 'Comments for recording:', 'Electrodes placed 5-10 mins prior to beginning of recording.', 'Baby born 20 minutes after the end of the recording.']}}\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(univariate_data_path, \"ehgdb1_univariate.npy\")\n",
    "target_data = np.load(save_dir, allow_pickle=True)\n",
    "print(len(target_data[0]['signal']))\n",
    "print(target_data[0])\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# data_dir = os.path.join(processed_data_path, dataset + \"_preprocessed.npy\")\n",
    "# or_dat = np.load(data_dir, allow_pickle=True)\n",
    "# # Select an instance\n",
    "# instance = or_dat[1]  # Using the provided index 1\n",
    "# print('original fs', instance['metadata']['fs'])\n",
    "# record_name = instance['record_name']\n",
    "# original_signals = instance['signal']  # Multivariate signals\n",
    "# print(original_signals)\n",
    "# fs = instance['metadata']['fs']\n",
    "\n",
    "# # Find the corresponding univariate signal\n",
    "# univariate_instance = univariate_data[1]\n",
    "# print(instance['record_name'], univariate_instance['record_name'])\n",
    "# univariate_signal = univariate_instance['signal']\n",
    "\n",
    "# # Determine the number of channels\n",
    "# num_channels = original_signals.shape[1]\n",
    "# print(num_channels)\n",
    "# sequence_length = original_signals.shape[0]\n",
    "\n",
    "# # Create subplots (num_channels + 1 to include the univariate signal)\n",
    "# fig, axs = plt.subplots(num_channels + 1, 1, figsize=(12, 2 * (num_channels + 1)), sharex=True)\n",
    "# time_axis = np.arange(sequence_length) / fs  # Convert to seconds\n",
    "\n",
    "# # Plot all original channels\n",
    "# title = f\"Original {num_channels}-Channel Signals & PCA-Reduced Univariate Signal ({record_name})\"\n",
    "# for i in range(num_channels):\n",
    "#     axs[i].plot(time_axis, original_signals[:, i], label=f'Channel {i+1}', color='b', alpha=0.7)\n",
    "#     axs[i].legend()\n",
    "#     axs[i].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# # Plot the univariate signal in a distinct color\n",
    "# axs[num_channels].plot(time_axis, univariate_signal, label=\"Univariate Signal (PCA)\", color='r')\n",
    "# axs[num_channels].legend()\n",
    "# axs[num_channels].set_ylabel(\"Amplitude\")\n",
    "# axs[num_channels].set_xlabel(\"Time (seconds)\")\n",
    "\n",
    "# fig.suptitle(title)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Select the downsampled signal\n",
    "# downsampled_signal = downsampled_data[1]['signal']\n",
    "# record_name = downsampled_data[1]['record_name']\n",
    "\n",
    "# # Create time axis assuming uniform sampling\n",
    "# downsampled_fs = 20  # The new sampling frequency\n",
    "# downsampled_time_axis = np.arange(len(downsampled_signal)) / downsampled_fs\n",
    "\n",
    "# # Plot the downsampled signal\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(downsampled_time_axis, downsampled_signal, label=\"Downsampled Signal\", color='g')\n",
    "# plt.xlabel(\"Time (seconds)\")\n",
    "# plt.ylabel(\"Amplitude\")\n",
    "# plt.title(f\"Downsampled Signal ({record_name}) at 20Hz\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import random\n",
    "\n",
    "# # Load dataset\n",
    "# data_path = os.path.join(univariate_data_path, dataset + \"_univariate.npy\")\n",
    "# data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "# # Select a random instance for visualization\n",
    "# random_instance = random.choice(data)\n",
    "# univariate_signal = random_instance['signal']  # Univariate after PCA\n",
    "\n",
    "# # Load the original dataset before PCA\n",
    "# original_data_path = os.path.join(processed_data_path, dataset + \"_preprocessed.npy\")\n",
    "# original_data = np.load(original_data_path, allow_pickle=True)\n",
    "\n",
    "# # Find the corresponding original signal\n",
    "# record_name = random_instance['record_name']\n",
    "# original_instance = next(entry for entry in original_data if entry['record_name'] == record_name)\n",
    "# original_multivariate_signal = original_instance['signal']  # Shape: (sequence_length, num_channels)\n",
    "\n",
    "# num_channels = original_multivariate_signal.shape[1]  \n",
    "\n",
    "# # Create subplots (num_channels + 1 to include the univariate signal)\n",
    "# fig, axs = plt.subplots(num_channels + 1, 1, figsize=(12, 2 * (num_channels + 1)), sharex=True)\n",
    "\n",
    "# time_axis = np.arange(original_multivariate_signal.shape[0])\n",
    "\n",
    "# # Plot all channels dynamically\n",
    "# for i in range(num_channels):\n",
    "#     axs[i].plot(time_axis, original_multivariate_signal[:, i], label=f'Channel {i+1}', color='b', alpha=0.7)\n",
    "#     axs[i].legend()\n",
    "#     axs[i].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# # Plot the univariate signal in a distinct color\n",
    "# axs[num_channels].plot(time_axis, univariate_signal, label=\"Univariate Signal (PCA)\", color='r')\n",
    "# axs[num_channels].legend()\n",
    "# axs[num_channels].set_ylabel(\"Amplitude\")\n",
    "# axs[num_channels].set_xlabel(\"Time\")\n",
    "\n",
    "# fig.suptitle(f\"Original {num_channels}-Channel Signal & PCA-Reduced Univariate Signal\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
