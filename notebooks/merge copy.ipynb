{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges all source data into one .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ehgdb1, shape: (61,)\n",
      "Loaded ehgdb2, shape: (62,)\n",
      "Loaded icehgds, shape: (126,)\n",
      "Loaded nifeadb, shape: (26,)\n",
      "Loaded ninfea, shape: (60,)\n",
      "Loaded tpehgdb, shape: (300,)\n",
      "Loaded tpehgt, shape: (31,)\n",
      "Saved merged dataset to ../data/univariate/merged_univariate.npy, shape: (666,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets = ['ehgdb1', 'ehgdb2', 'icehgds', 'nifeadb', 'ninfea', 'tpehgdb', 'tpehgt']\n",
    "data_list = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(univariate_data_path, dataset + \"_univariate.npy\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        data_list.append(data)\n",
    "        print(f\"Loaded {dataset}, shape: {data.shape}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Merge all datasets into one large NumPy array\n",
    "if data_list:\n",
    "    merged_data = np.concatenate(data_list, axis=0)  # Assuming they have the same structure\n",
    "    output_file = os.path.join(univariate_data_path, \"merged_univariate.npy\")\n",
    "    \n",
    "    np.save(output_file, merged_data)\n",
    "    print(f\"Saved merged dataset to {output_file}, shape: {merged_data.shape}\")\n",
    "else:\n",
    "    print(\"No data loaded. Check file paths.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully: ../data/univariate/merged_univariate.npy\n",
      "Total instances: 666\n",
      "\n",
      "First 3 entries:\n",
      "\n",
      "Entry 1:\n",
      "  Record Name: ice001_l_1of1\n",
      "  Signal Shape: (7600, 1)\n",
      "{'record_name': 'ice001_l_1of1', 'signal': array([[-1.7358303 ],\n",
      "       [-0.30347557],\n",
      "       [-0.40749874],\n",
      "       ...,\n",
      "       [-3.09738299],\n",
      "       [-2.90981482],\n",
      "       [-3.22768386]], shape=(7600, 1)), 'metadata': {'fs': 20, 'sig_len': 100000, 'n_sig': 16, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'comments': ['Info:', 'ID:ice001', 'Record type:labour', 'Record number:1/1', 'Age(years):31', 'BMI before pregnancy:23.3', 'BMI at recording:27.6', 'Gravidity:3', 'Parity:2', 'Previous caesarean:No', 'Placental position:Fundus', 'Gestational age at recording(w/d):39/3', 'Gestational age at delivery:39/3', 'Mode of delivery:Vaginal', 'Synthetic oxytocin use in labour:No', 'Epidural during labour:No', 'Comments for recording:', 'Electrodes placed 5-10 mins prior to beginning of recording.', 'Baby born 20 minutes after the end of the recording.']}}\n",
      "\n",
      "Entry 2:\n",
      "  Record Name: ice002_p_1of3\n",
      "  Signal Shape: (79300, 1)\n",
      "{'record_name': 'ice002_p_1of3', 'signal': array([[2.75807543],\n",
      "       [3.73701753],\n",
      "       [2.81895396],\n",
      "       ...,\n",
      "       [1.22541255],\n",
      "       [1.4427518 ],\n",
      "       [1.07846644]], shape=(79300, 1)), 'metadata': {'fs': 20, 'sig_len': 817000, 'n_sig': 16, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'comments': ['Info:', 'ID:ice002', 'Record type:pregnancy', 'Record number:1/3', 'Age(years):38', 'BMI before pregnancy:20.7', 'BMI at recording:25.9', 'Gravidity:4', 'Parity:1', 'Previous caesarean:No', 'Placental position:Posterior', 'Gestational age at recording(w/d):38/1', 'Gestational age at delivery:40/4', 'Mode of delivery:Vaginal', 'Synthetic oxytocin use in labour:No', 'Epidural during labour:No', 'Comments for recording:', 'The participant moved onto her left side at 00:25:50 due to nausea and faintness.', 'Comments for delivery:']}}\n",
      "\n",
      "Entry 3:\n",
      "  Record Name: ice002_p_2of3\n",
      "  Signal Shape: (72200, 1)\n",
      "{'record_name': 'ice002_p_2of3', 'signal': array([[-12.15116958],\n",
      "       [-24.48972151],\n",
      "       [-18.22349939],\n",
      "       ...,\n",
      "       [  3.40956282],\n",
      "       [  1.22642183],\n",
      "       [  4.90008321]], shape=(72200, 1)), 'metadata': {'fs': 20, 'sig_len': 746000, 'n_sig': 16, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'comments': ['Info:', 'ID:ice002', 'Record type:pregnancy', 'Record number:2/3', 'Age(years):38', 'BMI before pregnancy:20.7', 'BMI at recording:25.9', 'Gravidity:4', 'Parity:1', 'Previous caesarean:No', 'Placental position:Posterior', 'Gestational age at recording(w/d):39/1', 'Gestational age at delivery:40/4', 'Mode of delivery:Vaginal', 'Synthetic oxytocin use in labour:No', 'Epidural during labour:No', 'Comments for recording:', 'Reference on right hip - apparent reverse ECG.', 'Comments for delivery:']}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the merged dataset\n",
    "merged_file = os.path.join(univariate_data_path, \"merged_univariate.npy\")\n",
    "\n",
    "if os.path.exists(merged_file):\n",
    "    merged_data = np.load(merged_file, allow_pickle=True)\n",
    "    \n",
    "    # Print basic statistics\n",
    "    print(f\"Dataset loaded successfully: {merged_file}\")\n",
    "    print(f\"Total instances: {len(merged_data)}\")\n",
    "    \n",
    "    # Print first few entries as a \"header\"\n",
    "    print(\"\\nFirst 3 entries:\")\n",
    "    for i, entry in enumerate(merged_data[:3]):\n",
    "        print(f\"\\nEntry {i+1}:\")\n",
    "        print(f\"  Record Name: {entry['record_name']}\")\n",
    "        print(f\"  Signal Shape: {entry['signal'].shape}\")\n",
    "        print(entry)\n",
    "        # print(f\"  Metadata: {entry['metadata']}\")\n",
    "else:\n",
    "    print(f\"File not found: {merged_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
