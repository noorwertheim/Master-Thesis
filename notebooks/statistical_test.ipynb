{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path, results_path\n",
    "# Load data\n",
    "\n",
    "fcmae_path = os.path.join('..', 'results', 'FCMAE_resnet_subset_runs.csv')\n",
    "resnet_path = os.path.join('..', 'results', 'resnet_subset_runs.csv')\n",
    "fcmae_df = pd.read_csv(fcmae_path)\n",
    "resnet_df = pd.read_csv(resnet_path)\n",
    "\n",
    "# Add model label\n",
    "fcmae_df[\"model\"] = \"FCMAE+ResNet\"\n",
    "resnet_df[\"model\"] = \"ResNet\"\n",
    "\n",
    "# Combine into one DataFrame\n",
    "combined_df = pd.concat([fcmae_df, resnet_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data subset: 20\n",
      "accuracy: Shapiro-Wilk p = 0.3196 (normal)\n",
      "precision: Shapiro-Wilk p = 0.0371 (not normal)\n",
      "recall: Shapiro-Wilk p = 0.6337 (normal)\n",
      "f1: Shapiro-Wilk p = 0.1927 (normal)\n",
      "average_precision: Shapiro-Wilk p = 0.8567 (normal)\n",
      "roc_auc: Shapiro-Wilk p = 0.9912 (normal)\n",
      "\n",
      "Data subset: 40\n",
      "accuracy: Shapiro-Wilk p = 0.5318 (normal)\n",
      "precision: Shapiro-Wilk p = 0.1615 (normal)\n",
      "recall: Shapiro-Wilk p = 0.2914 (normal)\n",
      "f1: Shapiro-Wilk p = 0.5920 (normal)\n",
      "average_precision: Shapiro-Wilk p = 0.7330 (normal)\n",
      "roc_auc: Shapiro-Wilk p = 0.3840 (normal)\n",
      "\n",
      "Data subset: 60\n",
      "accuracy: Shapiro-Wilk p = 0.0215 (not normal)\n",
      "precision: Shapiro-Wilk p = 0.8360 (normal)\n",
      "recall: Shapiro-Wilk p = 0.1901 (normal)\n",
      "f1: Shapiro-Wilk p = 0.0083 (not normal)\n",
      "average_precision: Shapiro-Wilk p = 0.0763 (normal)\n",
      "roc_auc: Shapiro-Wilk p = 0.4624 (normal)\n",
      "\n",
      "Data subset: 80\n",
      "accuracy: Shapiro-Wilk p = 0.4643 (normal)\n",
      "precision: Shapiro-Wilk p = 0.4519 (normal)\n",
      "recall: Shapiro-Wilk p = 0.5016 (normal)\n",
      "f1: Shapiro-Wilk p = 0.0881 (normal)\n",
      "average_precision: Shapiro-Wilk p = 0.6223 (normal)\n",
      "roc_auc: Shapiro-Wilk p = 0.4042 (normal)\n",
      "\n",
      "Data subset: 100\n",
      "accuracy: Shapiro-Wilk p = 0.0659 (normal)\n",
      "precision: Shapiro-Wilk p = 0.1833 (normal)\n",
      "recall: Shapiro-Wilk p = 0.0361 (not normal)\n",
      "f1: Shapiro-Wilk p = 0.0457 (not normal)\n",
      "average_precision: Shapiro-Wilk p = 0.0584 (normal)\n",
      "roc_auc: Shapiro-Wilk p = 0.0009 (not normal)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'average_precision', 'roc_auc']\n",
    "subsets = sorted(fcmae_df['data_subset'].unique())\n",
    "\n",
    "for subset in subsets:\n",
    "    print(f\"\\nData subset: {subset}\")\n",
    "    \n",
    "    # Extract all runs for this subset (ignoring run order)\n",
    "    fcmae_subset = fcmae_df[fcmae_df['data_subset'] == subset].reset_index(drop=True)\n",
    "    resnet_subset = resnet_df[resnet_df['data_subset'] == subset].reset_index(drop=True)\n",
    "\n",
    "    # Align by index after ignoring run, assuming equal number of runs per subset\n",
    "    min_len = min(len(fcmae_subset), len(resnet_subset))\n",
    "    fcmae_subset = fcmae_subset.iloc[:min_len]\n",
    "    resnet_subset = resnet_subset.iloc[:min_len]\n",
    "\n",
    "    for metric in metrics:\n",
    "        fcmae_values = fcmae_subset[metric]\n",
    "        resnet_values = resnet_subset[metric]\n",
    "\n",
    "        # Compute differences without sorting to keep correct pairing\n",
    "        differences = fcmae_values - resnet_values\n",
    "        \n",
    "        # If differences have less than 3 unique values, shapiro test may give nan, so check:\n",
    "        if differences.nunique() < 3:\n",
    "            print(f\"{metric}: Not enough variation in differences for Shapiro-Wilk test (skipped)\")\n",
    "            continue\n",
    "        \n",
    "        stat, p_value = stats.shapiro(differences)\n",
    "        print(f\"{metric}: Shapiro-Wilk p = {p_value:.4f} {'(normal)' if p_value > 0.05 else '(not normal)'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "# Choose metric(s) to test\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"average_precision\", \"roc_auc\"]  # You can include more\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Loop over data subsets and metrics\n",
    "for subset in combined_df['data_subset'].unique():\n",
    "    for metric in metrics:\n",
    "        # Get values for each model\n",
    "        subset_df = combined_df[combined_df['data_subset'] == subset]\n",
    "        \n",
    "        fcmae_vals = subset_df[subset_df['model'] == \"FCMAE+ResNet\"][metric].values\n",
    "        resnet_vals = subset_df[subset_df['model'] == \"ResNet\"][metric].values\n",
    "\n",
    "        # Ensure equal-length pairing\n",
    "        if len(fcmae_vals) == len(resnet_vals):\n",
    "            try:\n",
    "                t_stat, t_p = ttest_rel(fcmae_vals, resnet_vals)\n",
    "                w_stat, w_p = wilcoxon(fcmae_vals, resnet_vals)\n",
    "                results.append({\n",
    "                    \"data_subset\": subset,\n",
    "                    \"metric\": metric,\n",
    "                    \"FCMAE+ResNet mean\": fcmae_vals.mean(),\n",
    "                    \"ResNet mean\": resnet_vals.mean(),\n",
    "                    \"wilcoxon_pval\": w_p\n",
    "                })\n",
    "            except ValueError:\n",
    "                # Wilcoxon might fail if all differences are zero\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    data_subset             metric  FCMAE+ResNet mean  ResNet mean  \\\n",
      "18           20           accuracy           0.570208     0.492604   \n",
      "22           20  average_precision           0.875769     0.889437   \n",
      "21           20                 f1           0.623484     0.493099   \n",
      "19           20          precision           0.907751     0.755044   \n",
      "20           20             recall           0.546561     0.383995   \n",
      "23           20            roc_auc           0.638773     0.690527   \n",
      "12           40           accuracy           0.645312     0.634792   \n",
      "16           40  average_precision           0.921155     0.924241   \n",
      "15           40                 f1           0.720573     0.706163   \n",
      "13           40          precision           0.913779     0.963914   \n",
      "14           40             recall           0.627381     0.557804   \n",
      "17           40            roc_auc           0.741529     0.742802   \n",
      "6            60           accuracy           0.596250     0.649479   \n",
      "10           60  average_precision           0.915016     0.909121   \n",
      "9            60                 f1           0.641472     0.725910   \n",
      "7            60          precision           0.913468     0.943616   \n",
      "8            60             recall           0.560979     0.590873   \n",
      "11           60            roc_auc           0.746275     0.736804   \n",
      "0            80           accuracy           0.583333     0.653958   \n",
      "4            80  average_precision           0.864779     0.908904   \n",
      "3            80                 f1           0.636590     0.732125   \n",
      "1            80          precision           0.879902     0.936192   \n",
      "2            80             recall           0.577381     0.602513   \n",
      "5            80            roc_auc           0.665717     0.737860   \n",
      "\n",
      "    wilcoxon_pval  \n",
      "18         0.6250  \n",
      "22         0.8125  \n",
      "21         0.4375  \n",
      "19         1.0000  \n",
      "20         0.4375  \n",
      "23         0.6250  \n",
      "12         0.6250  \n",
      "16         0.4375  \n",
      "15         0.6250  \n",
      "13         0.1875  \n",
      "14         0.6250  \n",
      "17         1.0000  \n",
      "6          1.0000  \n",
      "10         0.8125  \n",
      "9          0.6250  \n",
      "7          0.4375  \n",
      "8          0.6250  \n",
      "11         1.0000  \n",
      "0          0.6250  \n",
      "4          0.3125  \n",
      "3          0.8125  \n",
      "1          0.3125  \n",
      "2          1.0000  \n",
      "5          0.1250  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values([\"data_subset\", \"metric\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
