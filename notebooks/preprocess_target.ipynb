{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path\n",
    "from preprocessing_modules import EHGRecord, trim_target, filter_target, z_normalize_target, check_normalize_target, remove_records\n",
    "import scipy.io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_path = os.path.join(raw_data_path, 'target_data.npy')\n",
    "data = np.load(target_data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_to_remove = [\n",
    "    'Hopper-2022_02_10_06_02_17-0000010181-0012',\n",
    "    'Hopper-2022_10_02_01_32_56-0000010181-0002',\n",
    "    'Hopper-2022_10_23_16_07_47-0000010090-0001'\n",
    "]\n",
    "\n",
    "target_data = remove_records(data, records_to_remove)\n",
    "data = trim_target(data, 'target')\n",
    "data = filter_target(data)\n",
    "data = z_normalize_target(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(processed_data_path, 'target_preprocessed_old.npy')\n",
    "np.save(save_path, np.array(data, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of target\n",
      "../data/processed/target_preprocessed_old.npy\n",
      "type of data preprocessed:  <class 'numpy.ndarray'>\n",
      "Type of data_preprocessed: <class 'numpy.ndarray'>\n",
      "After unpacking, type: <class 'numpy.ndarray'>\n",
      "{'record_name': np.str_('Hopper-2023_05_25_12_03_38-0000010090-0003'), 'signal': array([[ -3.4528623 , -17.36775705, -11.05391952,  -3.46650686,\n",
      "         -2.6896713 ,  -1.84537916],\n",
      "       [ -3.39068175, -17.07373422, -10.8699895 ,  -3.41311593,\n",
      "         -2.6480211 ,  -1.81727669],\n",
      "       [ -3.32876095, -16.78078961, -10.68671023,  -3.35987783,\n",
      "         -2.60649057,  -1.78925403],\n",
      "       ...,\n",
      "       [  0.60066929,   0.2995247 ,   0.3930668 ,  -0.31037572,\n",
      "         -0.51762818,   0.23008789],\n",
      "       [  0.6006698 ,   0.29952186,   0.39306581,  -0.31037678,\n",
      "         -0.51762974,   0.23008839],\n",
      "       [  0.6006702 ,   0.29951964,   0.39306503,  -0.31037761,\n",
      "         -0.51763096,   0.23008877]]), 'fs': np.int64(128), 'preterm': 0}\n",
      "Total number of entries before: 168\n",
      "Total number of entries after: 168\n",
      "BEFORE PREPROCESSING\n",
      "Max sequence length: 18463872\n",
      "Min sequence length: 86400\n",
      "Mean sequence length: 1164518.10\n",
      "AFTER PREPROCESSING\n",
      "Max sequence length: 18448512\n",
      "Min sequence length: 71040\n",
      "Mean sequence length: 1146506.67\n",
      "Number of entries with 'preterm' as None: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'target'\n",
    "print('Statistics of', dataset_name)\n",
    "data_path_original = os.path.join(raw_data_path, dataset_name + '_data.npy')\n",
    "data_original = np.load(data_path_original, allow_pickle=True)\n",
    "data_path_preprocessed = os.path.join(processed_data_path, dataset_name + \"_preprocessed_old.npy\")\n",
    "print(data_path_preprocessed)\n",
    "data_preprocessed = np.load(data_path_preprocessed, allow_pickle=True)\n",
    "print('type of data preprocessed: ', type(data_preprocessed))\n",
    "print(\"Type of data_preprocessed:\", type(data_preprocessed))\n",
    "\n",
    "if isinstance(data_preprocessed, np.ndarray) and data_preprocessed.shape == ():\n",
    "    data_preprocessed = data_preprocessed.item()  # Unpack the object\n",
    "\n",
    "print(\"After unpacking, type:\", type(data_preprocessed))\n",
    "\n",
    "# If it's a list, access the first entry\n",
    "if isinstance(data_preprocessed, list):\n",
    "    print(\"First entry:\", data_preprocessed[0] if data_preprocessed else \"Empty dataset!\")\n",
    "\n",
    "\n",
    "print(data_preprocessed[0])\n",
    "print(f\"Total number of entries before: {len(data_original)}\")\n",
    "print(f\"Total number of entries after: {len(data_preprocessed)}\")\n",
    "# Extract sequence lengths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sequence_lengths_original = np.array([entry['signal'].shape[0] for entry in data_original])\n",
    "sequence_lengths_processed = np.array([entry['signal'].shape[0] for entry in data_preprocessed])\n",
    "\n",
    "# Compute statistics\n",
    "print('BEFORE PREPROCESSING')\n",
    "print(f\"Max sequence length: {np.max(sequence_lengths_original)}\")\n",
    "print(f\"Min sequence length: {np.min(sequence_lengths_original)}\")\n",
    "print(f\"Mean sequence length: {np.mean(sequence_lengths_original):.2f}\")\n",
    "# print(f\"Standard deviation of sequence lengths: {np.std(sequence_lengths):.2f}\"\n",
    "\n",
    "print('AFTER PREPROCESSING')\n",
    "print(f\"Max sequence length: {np.max(sequence_lengths_processed)}\")\n",
    "print(f\"Min sequence length: {np.min(sequence_lengths_processed)}\")\n",
    "print(f\"Mean sequence length: {np.mean(sequence_lengths_processed):.2f}\")\n",
    "\n",
    "# Count entries with 'preterm' as None\n",
    "none_count = sum(1 for entry in data_preprocessed if entry['preterm'] is None)\n",
    "\n",
    "print(f\"Number of entries with 'preterm' as None: {none_count}\")\n",
    "18463872 - 18463872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before preprocessing\n",
      "('Hopper-2023_05_25_12_03_38-0000010090-0003', array([[-1.14440918e-01, -1.14440918e-01,  0.00000000e+00,\n",
      "         1.14440918e-01,  0.00000000e+00,  1.14440918e-01],\n",
      "       [ 9.84191895e+00,  9.95635986e+00, -1.00708008e+01,\n",
      "        -1.99127197e+01,  1.14440918e-01, -2.00271606e+01],\n",
      "       [ 1.31607056e+01,  1.32751465e+01, -1.33895874e+01,\n",
      "        -2.65502930e+01,  1.14440918e-01, -2.66647339e+01],\n",
      "       ...,\n",
      "       [ 1.43051147e+02, -1.87088013e+03,  1.58718115e+03,\n",
      "         1.44413000e+03, -2.01393127e+03,  3.45806128e+03],\n",
      "       [ 1.82579041e+03, -1.36024475e+03, -1.47365576e+03,\n",
      "        -3.29944629e+03, -3.18603516e+03, -1.13411011e+02],\n",
      "       [ 1.91116333e+03, -9.61761475e+02, -1.79821021e+03,\n",
      "        -3.70937354e+03, -2.87292480e+03, -8.36448730e+02]], dtype=float32), 0, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwertheim/miniconda3/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('before preprocessing')\n",
    "sample_data = data_original[0]\n",
    "print(sample_data)\n",
    "# Extract the signal and sampling frequency\n",
    "signal = sample_data['signal']\n",
    "fs = sample_data['fs']\n",
    "\n",
    "# Create time axis based on the signal length and sampling frequency\n",
    "time = np.arange(len(signal)) / fs\n",
    "\n",
    "# Plot the signal\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, signal, label=f\"Signal for record: {sample_data['record_name']}\")\n",
    "plt.title(f\"Signal of {sample_data['record_name']}\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Signal Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('after preprocessing')\n",
    "sample_data = data_preprocessed[0]\n",
    "print(sample_data)\n",
    "# Extract the signal and sampling frequency\n",
    "signal = sample_data['signal']\n",
    "fs = sample_data['fs']\n",
    "\n",
    "# Create time axis based on the signal length and sampling frequency\n",
    "time = np.arange(len(signal)) / fs\n",
    "\n",
    "# Plot the signal\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, signal, label=f\"Signal for record: {sample_data['record_name']}\")\n",
    "plt.title(f\"Signal of {sample_data['record_name']}\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Signal Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
