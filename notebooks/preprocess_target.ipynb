{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path\n",
    "from preprocessing_modules import EHGRecord, trim_target, filter_target, z_normalize_target, check_normalize_target\n",
    "import scipy.io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_path = os.path.join(raw_data_path, 'target_data.npy')\n",
    "data = np.load(target_data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_to_remove = [\n",
    "    'Hopper-2022_02_10_06_02_17-0000010181-0012',\n",
    "    'Hopper-2022_10_02_01_32_56-0000010181-0002',\n",
    "    'Hopper-2022_10_23_16_07_47-0000010090-0001'\n",
    "]\n",
    "\n",
    "target_data = remove_records(target_data, records_to_remove)\n",
    "data = trim_target(data, 'target')\n",
    "data = filter_target(data)\n",
    "data = z_normalize_target(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(processed_data_path, 'target_preprocessed.npy')\n",
    "np.save(save_path, np.array(normalized_data, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of target\n",
      "../data/processed/target_preprocessed.npy\n",
      "type of data preprocessed:  <class 'numpy.ndarray'>\n",
      "Type of data_preprocessed: <class 'numpy.ndarray'>\n",
      "After unpacking, type: <class 'numpy.ndarray'>\n",
      "{'record_name': np.str_('Hopper-2023_05_25_12_03_38-0000010090-0003'), 'signal': array([[ -3.4528623 , -17.36775718, -11.05391955,  -3.46650686,\n",
      "         -2.68967131,  -1.84537917],\n",
      "       [ -3.39068175, -17.07373435, -10.86998952,  -3.41311592,\n",
      "         -2.64802111,  -1.8172767 ],\n",
      "       [ -3.32876095, -16.78078974, -10.68671026,  -3.35987782,\n",
      "         -2.60649058,  -1.78925404],\n",
      "       ...,\n",
      "       [  0.60066929,   0.2995247 ,   0.3930668 ,  -0.31037572,\n",
      "         -0.51762818,   0.2300879 ],\n",
      "       [  0.6006698 ,   0.29952187,   0.39306581,  -0.31037678,\n",
      "         -0.51762974,   0.23008839],\n",
      "       [  0.6006702 ,   0.29951964,   0.39306503,  -0.31037761,\n",
      "         -0.51763097,   0.23008878]], shape=(421248, 6)), 'preterm': 0}\n",
      "Total number of entries before: 167\n",
      "Total number of entries after: 164\n",
      "Max sequence length: 18463872\n",
      "Min sequence length: 86400\n",
      "Mean sequence length: 1169630.28\n",
      "Max sequence length: 18448512\n",
      "Min sequence length: 71040\n",
      "Mean sequence length: 1079262.44\n",
      "Number of entries with 'preterm' as None: 21\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'target'\n",
    "print('Statistics of', dataset_name)\n",
    "data_path_original = os.path.join(raw_data_path, dataset_name + '_data.npy')\n",
    "data_original = np.load(data_path_original, allow_pickle=True)\n",
    "data_path_preprocessed = os.path.join(processed_data_path, dataset_name + \"_preprocessed.npy\")\n",
    "print(data_path_preprocessed)\n",
    "data_preprocessed = np.load(data_path_preprocessed, allow_pickle=True)\n",
    "print('type of data preprocessed: ', type(data_preprocessed))\n",
    "print(\"Type of data_preprocessed:\", type(data_preprocessed))\n",
    "\n",
    "if isinstance(data_preprocessed, np.ndarray) and data_preprocessed.shape == ():\n",
    "    data_preprocessed = data_preprocessed.item()  # Unpack the object\n",
    "\n",
    "print(\"After unpacking, type:\", type(data_preprocessed))\n",
    "\n",
    "# If it's a list, access the first entry\n",
    "if isinstance(data_preprocessed, list):\n",
    "    print(\"First entry:\", data_preprocessed[0] if data_preprocessed else \"Empty dataset!\")\n",
    "\n",
    "\n",
    "print(data_preprocessed[0])\n",
    "print(f\"Total number of entries before: {len(data_original)}\")\n",
    "print(f\"Total number of entries after: {len(data_preprocessed)}\")\n",
    "# Extract sequence lengths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sequence_lengths_original = np.array([entry['signal'].shape[0] for entry in data_original])\n",
    "sequence_lengths_processed = np.array([entry['signal'].shape[0] for entry in data_preprocessed])\n",
    "\n",
    "# Compute statistics\n",
    "print(f\"Max sequence length: {np.max(sequence_lengths_original)}\")\n",
    "print(f\"Min sequence length: {np.min(sequence_lengths_original)}\")\n",
    "print(f\"Mean sequence length: {np.mean(sequence_lengths_original):.2f}\")\n",
    "# print(f\"Standard deviation of sequence lengths: {np.std(sequence_lengths):.2f}\")\n",
    "\n",
    "print(f\"Max sequence length: {np.max(sequence_lengths_processed)}\")\n",
    "print(f\"Min sequence length: {np.min(sequence_lengths_processed)}\")\n",
    "print(f\"Mean sequence length: {np.mean(sequence_lengths_processed):.2f}\")\n",
    "# Count entries with 'preterm' as None\n",
    "none_count = sum(1 for entry in data_preprocessed if entry['preterm'] is None)\n",
    "\n",
    "print(f\"Number of entries with 'preterm' as None: {none_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
