{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path\n",
    "from preprocessing_modules import create_time_windows_with_labels, create_time_windows_with_metadata\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import matplotlib.pyplot as plt\n",
    "from FCMAE_model import FCMAE\n",
    "from fastai.callback.tracker import SaveModelCallback, EarlyStoppingCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FCMAE Hyperparameters:\n",
    "batch_size = 16\n",
    "num_blocks = 5\n",
    "kernel_size = 7\n",
    "base_dim = 32\n",
    "learning_rate = 0.00016938000495408888\n",
    "input_dimension = 512\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import optuna\n",
    "from fastai.learner import Learner\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.metrics import accuracy\n",
    "from tsai.models.ResNet import ResNet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from fastai.optimizer import SGD\n",
    "# Load training data\n",
    "train_dir = os.path.join(univariate_data_path, \"target_univariate_no_PCA_train_2_80.npy\")\n",
    "train_data = np.load(train_dir, allow_pickle=True)\n",
    "train_windows, train_labels, train_meta = create_time_windows_with_metadata(train_data)\n",
    "\n",
    "# Convert to tensors\n",
    "train_windows_tensor = torch.tensor(train_windows, dtype=torch.float32).unsqueeze(1)  # shape: (N, 1, 12000)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Prepare dataset\n",
    "full_dataset = TensorDataset(train_windows_tensor, train_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the pre-trained encoder\n",
    "path = os.path.join(models_path, 'FCMAE_encoder_no_PCA_gpu_normalized_correct.pth')\n",
    "\n",
    "# Load the full FCMAE model\n",
    "fcmae = FCMAE(in_channels=1, base_dim=base_dim, num_blocks=num_blocks, kernel_size=kernel_size)\n",
    "\n",
    "\n",
    "# Load the saved weights into the full model\n",
    "state_dict = torch.load(path)\n",
    "fcmae.load_state_dict(state_dict)\n",
    "\n",
    "# Extract only the encoder from the FCMAE model\n",
    "encoder = fcmae.encoder\n",
    "# Set the encoder to evaluation mode and freeze the encoder parameters\n",
    "encoder.eval()\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False  # Freeze the encoder\n",
    "\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''tuneable optimizer, lower LR-range, early stopping'''\n",
    "from fastai.learner import Metric\n",
    "from sklearn.metrics import average_precision_score\n",
    "from fastai.optimizer import SGD, Adam\n",
    "\n",
    "\n",
    "# Custom Average Precision Metric\n",
    "class AveragePrecision(Metric):\n",
    "    def __init__(self):\n",
    "        self.pred = []\n",
    "        self.target = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.pred, self.target = [], []\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        preds = learn.pred.detach().softmax(dim=-1)[:, 1]\n",
    "        targs = learn.y.detach()\n",
    "        self.pred.append(preds.cpu())\n",
    "        self.target.append(targs.cpu())\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        preds = torch.cat(self.pred).numpy()\n",
    "        targs = torch.cat(self.target).numpy()\n",
    "        return average_precision_score(targs, preds)\n",
    "\n",
    "    @property\n",
    "    def name(self): return \"avg_precision\"\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-7, 1e-6)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['SGD', 'Adam'])\n",
    "\n",
    "    # Map optimizer name to fastai optimizer function\n",
    "    opt_func_map = {\n",
    "    'SGD': SGD,\n",
    "    'Adam': Adam,\n",
    "    }\n",
    "\n",
    "    opt_func = opt_func_map[optimizer_name]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    avg_precisions = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_windows_tensor, train_labels_tensor)):\n",
    "        train_subset = Subset(full_dataset, train_idx)\n",
    "        val_subset = Subset(full_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "        dls = DataLoaders(train_loader, val_loader)\n",
    "\n",
    "        class FCMAEClassifier(nn.Module):\n",
    "            def __init__(self, encoder):\n",
    "                super().__init__()\n",
    "                self.encoder = encoder\n",
    "                self.classifier = ResNet(input_dimension, 2)\n",
    "\n",
    "            def forward(self, x):\n",
    "                with torch.no_grad():\n",
    "                    x = self.encoder(x)\n",
    "                return self.classifier(x)\n",
    "\n",
    "        model = FCMAEClassifier(encoder).to(device)\n",
    "        loss_func = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "        learn = learn = Learner(\n",
    "            dls,\n",
    "            model,\n",
    "            loss_func=loss_func,\n",
    "            opt_func=opt_func,\n",
    "            metrics=accuracy,\n",
    "            cbs=[\n",
    "                EarlyStoppingCallback(monitor='valid_loss', patience=3),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        learn.fit_one_cycle(num_epochs, lr)\n",
    "        ap = learn.validate()[1]  # [loss, avg_precision]\n",
    "        avg_precisions.append(ap)\n",
    "\n",
    "    return np.mean(avg_precisions)  # maximize this\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n",
    "\n",
    "\n",
    "# Save the study\n",
    "import joblib\n",
    "joblib.dump(study, \"FCMAE_ResNet_tune_80.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''MY DATA'''\n",
    "# train_dir = os.path.join(univariate_data_path, \"target_univariate_no_PCA_train2.npy\")\n",
    "# train_data = np.load(train_dir, allow_pickle=True)\n",
    "# # train_data = pd.DataFrame(train_data)\n",
    "# test_dir = os.path.join(univariate_data_path, \"target_univariate_no_PCA_test2.npy\")\n",
    "# test_data = np.load(test_dir, allow_pickle=True)\n",
    "# # test_data = pd.DataFrame(test_data)\n",
    "# print(len(train_data))\n",
    "# print(len(test_data))\n",
    "# print(train_data[0])\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# # Example dataset with windows and labels\n",
    "# train_windows, train_labels = create_time_windows_with_labels(train_data)\n",
    "# test_windows, test_labels = create_time_windows_with_labels(test_data)\n",
    "\n",
    "# # Count label distribution\n",
    "# train_label_counts = Counter(train_labels)\n",
    "# test_label_counts = Counter(test_labels)\n",
    "\n",
    "# # Print the counts\n",
    "# print(\"Train label distribution:\")\n",
    "# print(f\"  Term (0): {train_label_counts[0]}\")\n",
    "# print(f\"  Preterm (1): {train_label_counts[1]}\")\n",
    "\n",
    "# print(\"\\nTest label distribution:\")\n",
    "# print(f\"  Term (0): {test_label_counts[0]}\")\n",
    "# print(f\"  Preterm (1): {test_label_counts[1]}\")\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# # Convert to tensors\n",
    "# train_windows_tensor = torch.tensor(train_windows, dtype=torch.float32)\n",
    "# train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32)\n",
    "# test_windows_tensor = torch.tensor(test_windows, dtype=torch.float32)\n",
    "# test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "# train_windows_tensor = train_windows_tensor.unsqueeze(1)  # (1071, 1, 12000)\n",
    "# test_windows_tensor = test_windows_tensor.unsqueeze(1)    # (899, 1, 12000)\n",
    "\n",
    "# train_labels_tensor = train_labels_tensor.long()\n",
    "# test_labels_tensor = test_labels_tensor.long()\n",
    "\n",
    "\n",
    "# print(train_labels_tensor.shape)\n",
    "\n",
    "# train_dataset = TensorDataset(train_windows_tensor, train_labels_tensor)\n",
    "# test_dataset = TensorDataset(test_windows_tensor, test_labels_tensor)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''CLASS WEIGHTS'''\n",
    "# from tsai.models.ResNet import ResNet\n",
    "# from tsai.models import ResNet\n",
    "# from tsai.models.ResNet import ResNet\n",
    "# from fastai.metrics import accuracy\n",
    "# from fastai.data.core import DataLoaders\n",
    "# from fastai.learner import Learner\n",
    "# import torch\n",
    "\n",
    "# class FCMAEClassifier(nn.Module):\n",
    "#     def __init__(self, encoder):\n",
    "#         super().__init__()\n",
    "#         self.encoder = encoder\n",
    "#         self.classifier = ResNet(2048, 2)  # 2048 channels from encoder, 2 output classes\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         with torch.no_grad():  # freeze encoder\n",
    "#             x = self.encoder(x)\n",
    "#         return self.classifier(x)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Wrap your DataLoaders and set device\n",
    "# dls = DataLoaders.from_dsets(\n",
    "#     train_dataset,\n",
    "#     test_dataset,\n",
    "#     bs=32,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0 \n",
    "# )\n",
    "\n",
    "# model = FCMAEClassifier(encoder)\n",
    "# model.to(device)\n",
    "\n",
    "# # Calculate class weights\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "# class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# # Use weighted loss\n",
    "# loss_func = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# # Replace your loss function in the learner\n",
    "# learn = Learner(dls, model, loss_func=loss_func, metrics=accuracy)\n",
    "# learn.fit_one_cycle(20, 1e-6)\n",
    "\n",
    "# learn.recorder.plot_loss()  # Plot loss curves (training and validation loss)\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import torch\n",
    "\n",
    "# # Get predictions and true labels\n",
    "# preds, targs = learn.get_preds(dl=learn.dls.valid)\n",
    "\n",
    "# # Convert predictions to class labels (argmax for multi-class classification)\n",
    "# pred_labels = preds.argmax(dim=1)\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cm = confusion_matrix(targs, pred_labels)\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "#             xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()\n",
    "\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score,\n",
    "#     precision_score,\n",
    "#     recall_score,\n",
    "#     f1_score,\n",
    "#     average_precision_score,\n",
    "#     roc_auc_score\n",
    "# )\n",
    "\n",
    "# # Convert to numpy arrays if needed\n",
    "# true_labels = targs.cpu().numpy()\n",
    "# pred_labels = pred_labels.cpu().numpy()\n",
    "# pred_probs = preds[:, 1].cpu().numpy()  # Probability of class 1\n",
    "\n",
    "# # Compute metrics\n",
    "# accuracy = accuracy_score(true_labels, pred_labels)\n",
    "# precision = precision_score(true_labels, pred_labels, zero_division=0)\n",
    "# recall = recall_score(true_labels, pred_labels, zero_division=0)\n",
    "# f1 = f1_score(true_labels, pred_labels, zero_division=0)\n",
    "# ap = average_precision_score(true_labels, pred_probs)\n",
    "# auc = roc_auc_score(true_labels, pred_probs)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"Average Precision (AP): {ap:.4f}\")\n",
    "# print(f\"Area Under ROC Curve (AUC): {auc:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
