{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Baseline classifier using train/test split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from CNN_classifier_model import CNNClassifier, train_model, evaluate_model\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path\n",
    "from preprocessing_modules import create_time_windows_with_labels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import wandb\n",
    "wandb.login(key=\"5f15eb7efc1e0e939ccc83345338a0b8c24e2fbc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Define a project name and other metadata\n",
    "wandb.init(\n",
    "    project=\"Baseline CNN classifier\",\n",
    "    name=\"run-without-class-weights\",  # Optional: to name the run\n",
    "    config={\n",
    "        \"learning_rate\": 0.00012403724372113712,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 16,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(univariate_data_path, \"target_univariate_train.npy\")\n",
    "train_data = np.load(train_dir, allow_pickle=True)\n",
    "# train_data = pd.DataFrame(train_data)\n",
    "test_dir = os.path.join(univariate_data_path, \"target_univariate_test.npy\")\n",
    "test_data = np.load(test_dir, allow_pickle=True)\n",
    "# test_data = pd.DataFrame(test_data)\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(train_data[0])\n",
    "\n",
    "train_windows = create_time_windows_with_labels(train_data)\n",
    "test_windows = create_time_windows_with_labels(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00012403724372113712\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "num_layers = 5\n",
    "base_channels = 32\n",
    "device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Example dataset with windows and labels\n",
    "train_windows, train_labels = create_time_windows_with_labels(train_data)\n",
    "test_windows, test_labels = create_time_windows_with_labels(test_data)\n",
    "\n",
    "# Count label distribution\n",
    "train_label_counts = Counter(train_labels)\n",
    "test_label_counts = Counter(test_labels)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Train label distribution:\")\n",
    "print(f\"  Term (0): {train_label_counts[0]}\")\n",
    "print(f\"  Preterm (1): {train_label_counts[1]}\")\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(f\"  Term (0): {test_label_counts[0]}\")\n",
    "print(f\"  Preterm (1): {test_label_counts[1]}\")\n",
    "\n",
    "# Convert to tensors\n",
    "train_windows_tensor = torch.tensor(train_windows, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32)\n",
    "test_windows_tensor = torch.tensor(test_windows, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_windows_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_windows_tensor, test_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "input_length = 12000\n",
    "model = CNNClassifier(input_length=input_length, num_layers=num_layers, base_channels=base_channels)\n",
    "model = model.to(device)\n",
    "wandb.watch(model, log='all', log_freq=10)\n",
    "# print(model)\n",
    "# Train\n",
    "model = train_model(model, train_loader, test_loader, epochs=epochs, lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
