{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Baseline classifier using train/test split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nwertheim/miniconda3/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from CNN_classifier_model import CNNClassifier, train_model\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path\n",
    "from preprocessing_modules import create_time_windows_with_labels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import wandb\n",
    "wandb.login(key=\"5f15eb7efc1e0e939ccc83345338a0b8c24e2fbc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-with-class-weights</strong> at: <a href='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier/runs/ckh0hsq5' target=\"_blank\">https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier/runs/ckh0hsq5</a><br> View project at: <a href='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier' target=\"_blank\">https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250429_100825-ckh0hsq5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/gpfs/home3/nwertheim/Master-Thesis/notebooks/wandb/run-20250429_100852-4r02vc6w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier/runs/4r02vc6w' target=\"_blank\">run-with-class-weights2</a></strong> to <a href='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier' target=\"_blank\">https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier/runs/4r02vc6w' target=\"_blank\">https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier/runs/4r02vc6w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/noorwertheim/Baseline%20CNN%20classifier/runs/4r02vc6w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1531d12a7440>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Optional: Define a project name and other metadata\n",
    "wandb.init(\n",
    "    project=\"Baseline CNN classifier\",\n",
    "    name=\"run-with-class-weights2\",  # Optional: to name the run\n",
    "    config={\n",
    "        \"learning_rate\": 0.00012403724372113712,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 16,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "32\n",
      "{'record_name': np.str_('Hopper-2022_08_24_06_55_46-0000010181-0001'), 'signal': array([[ -8.77326634],\n",
      "       [-16.30170858],\n",
      "       [-12.15312614],\n",
      "       ...,\n",
      "       [  1.94513686],\n",
      "       [  0.52803341],\n",
      "       [  2.90890496]]), 'fs': 20, 'preterm': 1}\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(univariate_data_path, \"target_univariate_train.npy\")\n",
    "train_data = np.load(train_dir, allow_pickle=True)\n",
    "# train_data = pd.DataFrame(train_data)\n",
    "test_dir = os.path.join(univariate_data_path, \"target_univariate_test.npy\")\n",
    "test_data = np.load(test_dir, allow_pickle=True)\n",
    "# test_data = pd.DataFrame(test_data)\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(train_data[0])\n",
    "\n",
    "train_windows = create_time_windows_with_labels(train_data)\n",
    "test_windows = create_time_windows_with_labels(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00012403724372113712\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "num_layers = 5\n",
    "base_channels = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution:\n",
      "  Term (0): 319\n",
      "  Preterm (1): 752\n",
      "\n",
      "Test label distribution:\n",
      "  Term (0): 306\n",
      "  Preterm (1): 593\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Example dataset with windows and labels\n",
    "train_windows, train_labels = create_time_windows_with_labels(train_data)\n",
    "test_windows, test_labels = create_time_windows_with_labels(test_data)\n",
    "\n",
    "# Count label distribution\n",
    "train_label_counts = Counter(train_labels)\n",
    "test_label_counts = Counter(test_labels)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Train label distribution:\")\n",
    "print(f\"  Term (0): {train_label_counts[0]}\")\n",
    "print(f\"  Preterm (1): {train_label_counts[1]}\")\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(f\"  Term (0): {test_label_counts[0]}\")\n",
    "print(f\"  Preterm (1): {test_label_counts[1]}\")\n",
    "\n",
    "# Convert to tensors\n",
    "train_windows_tensor = torch.tensor(train_windows, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32)\n",
    "test_windows_tensor = torch.tensor(test_windows, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_windows_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_windows_tensor, test_labels_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_windows_from_signal(signal, window_size):\n",
    "#     signal = signal.squeeze()  # (seq_len,)\n",
    "#     total_length = len(signal)\n",
    "#     n_windows = total_length // window_size\n",
    "#     windows = np.array([\n",
    "#         signal[i * window_size: (i + 1) * window_size]\n",
    "#         for i in range(n_windows)\n",
    "#     ])\n",
    "#     return windows  # shape (n_windows, window_size)\n",
    "\n",
    "# def create_windowed_dataset(df, window_size):\n",
    "#     windowed_data = []  \n",
    "\n",
    "#     for idx, row in df.iterrows():\n",
    "#         record_name = row[0]['record_name']\n",
    "#         label = row[0]['preterm']\n",
    "#         signal = row[0]['signal']  # shape (seq_len, 1)\n",
    "\n",
    "#         windows = extract_windows_from_signal(signal, window_size)\n",
    "\n",
    "#         for i, window in enumerate(windows):\n",
    "#             windowed_data.append({\n",
    "#                 'record_name': record_name,\n",
    "#                 'window_id': i,\n",
    "#                 'window': window.astype(np.float32),\n",
    "#                 'label': label\n",
    "#             })\n",
    "\n",
    "#     return pd.DataFrame(windowed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TimeSeriesWindowDataset(Dataset):\n",
    "#     def __init__(self, dataframe):\n",
    "#         self.data = dataframe\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         row = self.data.iloc[idx]\n",
    "#         window = torch.tensor(row['window']).unsqueeze(0)  # shape (1, window_size)\n",
    "#         label = torch.tensor(row['label'], dtype=torch.float32)\n",
    "#         return window, label\n",
    "\n",
    "# def create_dataloaders(train_df, test_df, batch_size=32):\n",
    "#     train_loader = DataLoader(TimeSeriesWindowDataset(train_df), batch_size=batch_size, shuffle=True)\n",
    "#     test_loader = DataLoader(TimeSeriesWindowDataset(test_df), batch_size=batch_size, shuffle=False)\n",
    "#     return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size = 12000\n",
    "\n",
    "# # 1. Create windows\n",
    "# train_windows = create_windowed_dataset(train_data, window_size=window_size)\n",
    "# test_windows = create_windowed_dataset(test_data, window_size=window_size)\n",
    "\n",
    "# # 3. Create DataLoaders\n",
    "# train_loader, test_loader = create_dataloaders(train_windows, test_windows)\n",
    "# print(len(train_loader), len(test_loader))\n",
    "\n",
    "# def print_class_distribution(df, name=\"Dataset\"):\n",
    "#     class_counts = df['label'].value_counts().sort_index()\n",
    "#     total_count = len(df)\n",
    "    \n",
    "#     term_count = class_counts.get(0, 0)  # count for term (0)\n",
    "#     preterm_count = class_counts.get(1, 0)  # count for preterm (1)\n",
    "    \n",
    "#     term_ratio = term_count / total_count\n",
    "#     preterm_ratio = preterm_count / total_count\n",
    "    \n",
    "#     print(f\"\\n{name} class distribution:\")\n",
    "#     print(f\"Term (0): {term_count} instances, {term_ratio:.2f} ratio\")\n",
    "#     print(f\"Preterm (1): {preterm_count} instances, {preterm_ratio:.2f} ratio\")\n",
    "#     print(f\"Total: {total_count} instances\")\n",
    "\n",
    "# # For train and test\n",
    "# print_class_distribution(train_windows, \"Train Set\")\n",
    "# print_class_distribution(test_windows, \"Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class CNNClassifier(nn.Module):\n",
    "#     def __init__(self, input_length):\n",
    "#         super(CNNClassifier, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3)\n",
    "#         self.bn1 = nn.BatchNorm1d(16)\n",
    "        \n",
    "#         self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
    "#         self.bn2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "#         self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "#         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.classifier = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))  # (B, 16, L)\n",
    "#         x = F.relu(self.bn2(self.conv2(x)))  # (B, 32, L)\n",
    "#         x = F.relu(self.bn3(self.conv3(x)))  # (B, 64, L)\n",
    "        \n",
    "#         x = self.pool(x).squeeze(-1)         # (B, 64)\n",
    "#         x = self.classifier(x)               # (B, 1)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# def train_model(model, train_loader, test_loader, epochs=10, lr=1e-3, device='cuda'):\n",
    "#     device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     # Extract labels to compute class weights\n",
    "#     all_labels = []\n",
    "#     for _, y_batch in train_loader:\n",
    "#         all_labels.extend(y_batch.numpy())\n",
    "\n",
    "#     class_weights = compute_class_weight(\n",
    "#         class_weight='balanced',\n",
    "#         classes=np.array([0, 1]),\n",
    "#         y=np.array(all_labels)\n",
    "#     )\n",
    "    \n",
    "#     pos_weight = torch.tensor(class_weights[1] / class_weights[0], dtype=torch.float).to(device)\n",
    "#     # criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     # Lists to store epoch-wise losses\n",
    "#     train_losses = []\n",
    "#     test_losses = []\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         epoch_train_loss = 0.0\n",
    "\n",
    "#         for x_batch, y_batch in train_loader:\n",
    "#             x_batch = x_batch.unsqueeze(1).to(device)  # Add channel dim: (B, 1, L)\n",
    "#             y_batch = y_batch.to(device).unsqueeze(1)  # (B,) â†’ (B, 1)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(x_batch)\n",
    "#             loss = criterion(outputs, y_batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             epoch_train_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "#         avg_train_loss = epoch_train_loss / len(train_loader.dataset)\n",
    "#         train_losses.append(avg_train_loss)\n",
    "\n",
    "#         # Evaluate on test set\n",
    "#         model.eval()\n",
    "#         epoch_test_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for x_batch, y_batch in test_loader:\n",
    "#                 x_batch = x_batch.unsqueeze(1).to(device)\n",
    "#                 y_batch = y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "#                 outputs = model(x_batch)\n",
    "#                 loss = criterion(outputs, y_batch)\n",
    "#                 epoch_test_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "#         avg_test_loss = epoch_test_loss / len(test_loader.dataset)\n",
    "#         test_losses.append(avg_test_loss)\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "#     # Plot loss curves\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "#     plt.plot(test_losses, label=\"Test Loss\", marker='s')\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.title(\"Training and Test Loss per Epoch\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def evaluate_model(model, dataloader, criterion, device='cuda'):\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     all_preds = []\n",
    "#     all_probs = []\n",
    "#     all_labels = []\n",
    "#     device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for x_batch, y_batch in dataloader:\n",
    "#             x_batch = x_batch.to(device)\n",
    "#             y_batch = y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "#             outputs = model(x_batch)\n",
    "#             probs = torch.sigmoid(outputs)\n",
    "#             loss = criterion(outputs, y_batch)\n",
    "\n",
    "#             total_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "#             all_probs.append(probs.cpu())\n",
    "#             all_preds.append((probs >= 0.5).float().cpu())\n",
    "#             all_labels.append(y_batch.cpu())\n",
    "\n",
    "#     all_probs = torch.cat(all_probs).numpy().flatten()\n",
    "#     all_preds = torch.cat(all_preds).numpy().flatten()\n",
    "#     all_labels = torch.cat(all_labels).numpy().flatten()\n",
    "\n",
    "#     avg_loss = total_loss / len(dataloader.dataset)\n",
    "#     acc = (all_preds == all_labels).mean()\n",
    "#     auc = roc_auc_score(all_labels, all_probs)\n",
    "#     ap = average_precision_score(all_labels, all_probs)\n",
    "    \n",
    "#     print(f\"Loss: {avg_loss:.4f} | Acc: {acc:.4f} | AUC: {auc:.4f} | AP: {ap:.4f}\")\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "#     # Plot confusion matrix\n",
    "#     cm = confusion_matrix(all_labels, all_preds)\n",
    "#     plot_confusion_matrix(cm, class_names=[\"Term\", \"Preterm\"])\n",
    "    \n",
    "#     return avg_loss, acc, auc, ap\n",
    "\n",
    "# def plot_confusion_matrix(cm, class_names):\n",
    "#     plt.figure(figsize=(6, 5))\n",
    "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "#                 xticklabels=class_names, yticklabels=class_names)\n",
    "#     plt.xlabel(\"Predicted\")\n",
    "#     plt.ylabel(\"True\")\n",
    "#     plt.title(\"Confusion Matrix\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Test Loss (pre-update): 0.4301 | Train Loss: 0.3977\n",
      "Epoch 2/10 | Test Loss (pre-update): 0.5052 | Train Loss: 0.3963\n",
      "Epoch 3/10 | Test Loss (pre-update): 0.5114 | Train Loss: 0.3877\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m wandb.watch(model, log=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home3/nwertheim/Master-Thesis/notebooks/CNN_classifier_model.py:101\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, epochs, lr, device)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1790\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1796\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1797\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m   1799\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home3/nwertheim/Master-Thesis/notebooks/CNN_classifier_model.py:47\u001b[39m, in \u001b[36mCNNClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m conv, bn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.convs, \u001b[38;5;28mself\u001b[39m.bns):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m         x = F.relu(\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (B, C, L)\u001b[39;00m\n\u001b[32m     49\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.pool(x).squeeze(-\u001b[32m1\u001b[39m)   \u001b[38;5;66;03m# (B, C)\u001b[39;00m\n\u001b[32m     50\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.classifier(x)         \u001b[38;5;66;03m# (B, 1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "input_length = 12000\n",
    "model = CNNClassifier(input_length=input_length, num_layers=num_layers, base_channels=base_channels)\n",
    "wandb.watch(model, log='all')\n",
    "# print(model)\n",
    "# Train\n",
    "model = train_model(model, train_loader, test_loader, epochs=epochs, lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation Metrics:\n",
      "Accuracy:  0.6129\n",
      "Precision: 0.6804\n",
      "Recall:    0.7791\n",
      "F1 Score:  0.7264\n",
      "AUC:       0.6344\n",
      "AP:        0.7330\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, average_precision_score, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.unsqueeze(1).to(device)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "            logits = model(x_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy().flatten())\n",
    "            all_preds.extend((probs > 0.5).int().cpu().numpy().flatten())\n",
    "            all_labels.extend(y_batch.cpu().numpy().flatten())\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_score = np.array(all_probs)\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    ap = average_precision_score(y_true, y_score)\n",
    "\n",
    "    print(\"\\n Evaluation Metrics:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"AUC:       {auc:.4f}\")\n",
    "    print(f\"AP:        {ap:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Term\", \"Preterm\"])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
