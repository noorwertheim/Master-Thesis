{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nwertheim/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "{'record_name': np.str_('Hopper-2023_05_25_12_03_38-0000010090-0003'), 'signal': array([[-0.70613831],\n",
      "       [-0.9054771 ],\n",
      "       [-0.7669727 ],\n",
      "       ...,\n",
      "       [-0.4010203 ],\n",
      "       [-0.44152144],\n",
      "       [-0.37364218]]), 'fs': 20, 'preterm': 0}\n",
      "Number of instances with None in 'preterm': 12\n",
      "Remaining instances after deletion: 156\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(univariate_data_path, \"target_univariate.npy\")\n",
    "target_data = np.load(save_dir, allow_pickle=True)\n",
    "print(len(target_data))\n",
    "print(target_data[0])\n",
    "num_none_preterm = sum(1 for item in target_data if item['preterm'] is None)\n",
    "print(f\"Number of instances with None in 'preterm': {num_none_preterm}\")\n",
    "target_data = [item for item in target_data if item['preterm'] is not None]\n",
    "print(f\"Remaining instances after deletion: {len(target_data)}\")\n",
    "\n",
    "target_data = pd.DataFrame(target_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows_from_signal(signal, window_size):\n",
    "    signal = signal.squeeze()  # (seq_len,)\n",
    "    total_length = len(signal)\n",
    "    n_windows = total_length // window_size\n",
    "    windows = np.array([\n",
    "        signal[i * window_size: (i + 1) * window_size]\n",
    "        for i in range(n_windows)\n",
    "    ])\n",
    "    return windows  # shape (n_windows, window_size)\n",
    "\n",
    "def create_windowed_dataset(df, window_size):\n",
    "    windowed_data = []  \n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        record_name = row['record_name']\n",
    "        label = row['preterm']\n",
    "        signal = row['signal']  # shape (seq_len, 1)\n",
    "\n",
    "        windows = extract_windows_from_signal(signal, window_size)\n",
    "\n",
    "        for i, window in enumerate(windows):\n",
    "            windowed_data.append({\n",
    "                'record_name': record_name,\n",
    "                'window_id': i,\n",
    "                'window': window.astype(np.float32),\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(windowed_data)\n",
    "\n",
    "\n",
    "def split_data(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    assert np.isclose(train_ratio + val_ratio + test_ratio, 1.0), \"Splits must sum to 1.\"\n",
    "\n",
    "    # First split off the test set\n",
    "    train_val_df, test_df = train_test_split(df, test_size=test_ratio, stratify=df['label'], random_state=42)\n",
    "\n",
    "    # Now split train and val from the remaining part\n",
    "    val_adjusted = val_ratio / (train_ratio + val_ratio)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_adjusted, stratify=train_val_df['label'], random_state=42)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesWindowDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        window = torch.tensor(row['window']).unsqueeze(0)  # shape (1, window_size)\n",
    "        label = torch.tensor(row['label'], dtype=torch.float32)\n",
    "        return window, label\n",
    "\n",
    "def create_dataloaders(train_df, val_df, test_df, batch_size=32):\n",
    "    train_loader = DataLoader(TimeSeriesWindowDataset(train_df), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TimeSeriesWindowDataset(val_df), batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(TimeSeriesWindowDataset(test_df), batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1576 197 197\n",
      "\n",
      "Train Set class distribution:\n",
      "Term (0): 500 instances, 0.32 ratio\n",
      "Preterm (1): 1076 instances, 0.68 ratio\n",
      "Total: 1576 instances\n",
      "\n",
      "Test Set class distribution:\n",
      "Term (0): 63 instances, 0.32 ratio\n",
      "Preterm (1): 134 instances, 0.68 ratio\n",
      "Total: 197 instances\n"
     ]
    }
   ],
   "source": [
    "window_size = 12000\n",
    "\n",
    "# 1. Create windows\n",
    "windowed_df = create_windowed_dataset(target_data, window_size=window_size)\n",
    "label_col = \"label\"  # or \"preterm\", etc.\n",
    "\n",
    "\n",
    "# Split into positives and negatives\n",
    "positive_df = windowed_df[windowed_df[label_col] == 1]\n",
    "negative_df = windowed_df[windowed_df[label_col] == 0]\n",
    "\n",
    "# Get the smaller class size\n",
    "min_class_size = min(len(positive_df), len(negative_df))\n",
    "\n",
    "# Sample both classes equally\n",
    "balanced_positive = positive_df.sample(n=min_class_size, random_state=42)\n",
    "balanced_negative = negative_df.sample(n=min_class_size, random_state=42)\n",
    "\n",
    "# Concatenate and shuffle\n",
    "balanced_df = pd.concat([balanced_positive, balanced_negative]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 2. Split data\n",
    "train_df, val_df, test_df = split_data(windowed_df)\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(train_df, val_df, test_df)\n",
    "print(len(train_df), len(test_df), len(val_df))\n",
    "\n",
    "def print_class_distribution(df, name=\"Dataset\"):\n",
    "    class_counts = df['label'].value_counts().sort_index()\n",
    "    total_count = len(df)\n",
    "    \n",
    "    term_count = class_counts.get(0, 0)  # count for term (0)\n",
    "    preterm_count = class_counts.get(1, 0)  # count for preterm (1)\n",
    "    \n",
    "    term_ratio = term_count / total_count\n",
    "    preterm_ratio = preterm_count / total_count\n",
    "    \n",
    "    print(f\"\\n{name} class distribution:\")\n",
    "    print(f\"Term (0): {term_count} instances, {term_ratio:.2f} ratio\")\n",
    "    print(f\"Preterm (1): {preterm_count} instances, {preterm_ratio:.2f} ratio\")\n",
    "    print(f\"Total: {total_count} instances\")\n",
    "\n",
    "# For train and test\n",
    "print_class_distribution(train_df, \"Train Set\")\n",
    "print_class_distribution(test_df, \"Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 16, L)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 32, L)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 64, L)\n",
    "        \n",
    "        x = self.pool(x).squeeze(-1)         # (B, 64)\n",
    "        x = self.classifier(x)               # (B, 1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_roc_and_pr_curve(y_true, y_probs):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
    "    pr_auc = average_precision_score(y_true, y_probs)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AP = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-3, device='cuda'):\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Extract labels from the dataset to compute class weights\n",
    "    all_labels = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        all_labels.extend(y_batch.numpy())  # Extract labels from the batch\n",
    "\n",
    "    # Compute class weights based on the label distribution in the training set\n",
    "    class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1]),  # <-- convert list to np.array\n",
    "    y=np.array(all_labels)     # ensure labels are also a NumPy array\n",
    "    )\n",
    "    \n",
    "    # Convert class weights to a tensor\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    # Create the loss function with class weights\n",
    "    # class_weights[1] corresponds to the minority (positive) class\n",
    "    pos_weight = torch.tensor(class_weights[1] / class_weights[0], dtype=torch.float).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Initialize lists to store true labels and predicted probabilities\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)  # (B, 1, window_size)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)  # (B, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        # Evaluate on the validation set and collect labels and predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "                outputs = model(x_batch)\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()  # Get probabilities\n",
    "\n",
    "                all_labels.extend(y_batch.cpu().numpy().flatten())  # True labels\n",
    "                all_probs.extend(probs.flatten())  # Predicted probabilities\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        # val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "        # print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss/len(train_loader.dataset):.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss/len(train_loader.dataset):.4f}\")\n",
    "        # After each epoch, plot ROC and PR curves\n",
    "        # plot_roc_and_pr_curve(all_labels, all_probs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "            outputs = model(x_batch)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            total_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_preds.append((probs >= 0.5).float().cpu())\n",
    "            all_labels.append(y_batch.cpu())\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy().flatten()\n",
    "    all_preds = torch.cat(all_preds).numpy().flatten()\n",
    "    all_labels = torch.cat(all_labels).numpy().flatten()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    acc = (all_preds == all_labels).mean()\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    ap = average_precision_score(all_labels, all_probs)\n",
    "    \n",
    "    print(f\"Loss: {avg_loss:.4f} | Acc: {acc:.4f} | AUC: {auc:.4f} | AP: {ap:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plot_confusion_matrix(cm, class_names=[\"Term\", \"Preterm\"])\n",
    "    \n",
    "    return avg_loss, acc, auc, ap\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model = CNNClassifier(input_length=input_length)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, lr, device)\u001b[39m\n\u001b[32m     77\u001b[39m outputs = model(x_batch)\n\u001b[32m     78\u001b[39m loss = criterion(outputs, y_batch)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m optimizer.step()\n\u001b[32m     82\u001b[39m train_loss += loss.item() * x_batch.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_length = 12000\n",
    "model = CNNClassifier(input_length=input_length)\n",
    "\n",
    "# Train\n",
    "model = train_model(model, train_loader, val_loader, epochs=20, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6302 | Acc: 0.5876 | AUC: 0.6407 | AP: 0.8088\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3444    0.6889    0.4593        45\n",
      "         1.0     0.8391    0.5530    0.6667       132\n",
      "\n",
      "    accuracy                         0.5876       177\n",
      "   macro avg     0.5918    0.6210    0.5630       177\n",
      "weighted avg     0.7133    0.5876    0.6139       177\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, test_acc, test_auc, test_ap = evaluate_model(model, test_loader, nn.BCEWithLogitsLoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
