{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:28:52.813898: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.5785 - loss: 0.7059 - val_accuracy: 0.5806 - val_loss: 0.6825\n",
      "Epoch 2/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 0.6651 - val_accuracy: 0.5569 - val_loss: 0.6907\n",
      "Epoch 3/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.5933 - loss: 0.6611 - val_accuracy: 0.5093 - val_loss: 0.6994\n",
      "Epoch 4/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6026 - loss: 0.6593 - val_accuracy: 0.5381 - val_loss: 0.6965\n",
      "Epoch 5/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6091 - loss: 0.6565 - val_accuracy: 0.5853 - val_loss: 0.6885\n",
      "Epoch 6/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6121 - loss: 0.6552 - val_accuracy: 0.5950 - val_loss: 0.6878\n",
      "Epoch 7/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.6534 - val_accuracy: 0.5918 - val_loss: 0.6878\n",
      "Epoch 8/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6151 - loss: 0.6527 - val_accuracy: 0.6059 - val_loss: 0.6859\n",
      "Epoch 9/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6161 - loss: 0.6517 - val_accuracy: 0.6084 - val_loss: 0.6832\n",
      "Epoch 10/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6150 - loss: 0.6515 - val_accuracy: 0.6070 - val_loss: 0.6859\n",
      "Epoch 11/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6162 - loss: 0.6507 - val_accuracy: 0.5980 - val_loss: 0.6883\n",
      "Epoch 12/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6170 - loss: 0.6504 - val_accuracy: 0.6160 - val_loss: 0.6800\n",
      "Epoch 13/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.6498 - val_accuracy: 0.6144 - val_loss: 0.6852\n",
      "Epoch 14/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.6495 - val_accuracy: 0.5971 - val_loss: 0.6890\n",
      "Epoch 15/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 0.6489 - val_accuracy: 0.5843 - val_loss: 0.6917\n",
      "Epoch 16/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6184 - loss: 0.6486 - val_accuracy: 0.6135 - val_loss: 0.6842\n",
      "Epoch 17/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6188 - loss: 0.6483 - val_accuracy: 0.6121 - val_loss: 0.6850\n",
      "Epoch 18/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 0.6473 - val_accuracy: 0.6122 - val_loss: 0.6840\n",
      "Epoch 19/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 0.6475 - val_accuracy: 0.6174 - val_loss: 0.6826\n",
      "Epoch 20/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6193 - loss: 0.6472 - val_accuracy: 0.6144 - val_loss: 0.6836\n",
      "Epoch 21/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6205 - loss: 0.6462 - val_accuracy: 0.6122 - val_loss: 0.6847\n",
      "Epoch 22/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 0.6465 - val_accuracy: 0.5938 - val_loss: 0.6926\n",
      "Epoch 23/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6201 - loss: 0.6461 - val_accuracy: 0.6138 - val_loss: 0.6842\n",
      "Epoch 24/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6208 - loss: 0.6459 - val_accuracy: 0.5737 - val_loss: 0.6930\n",
      "Epoch 25/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6218 - loss: 0.6450 - val_accuracy: 0.6091 - val_loss: 0.6876\n",
      "Epoch 26/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6224 - loss: 0.6449 - val_accuracy: 0.6142 - val_loss: 0.6857\n",
      "Epoch 27/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6216 - loss: 0.6451 - val_accuracy: 0.6165 - val_loss: 0.6833\n",
      "Epoch 28/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6212 - loss: 0.6452 - val_accuracy: 0.6165 - val_loss: 0.6819\n",
      "Epoch 29/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6215 - loss: 0.6445 - val_accuracy: 0.5987 - val_loss: 0.6887\n",
      "Epoch 30/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6226 - loss: 0.6440 - val_accuracy: 0.5804 - val_loss: 0.6919\n",
      "Epoch 31/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6210 - loss: 0.6442 - val_accuracy: 0.6111 - val_loss: 0.6867\n",
      "Epoch 32/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6218 - loss: 0.6438 - val_accuracy: 0.6043 - val_loss: 0.6891\n",
      "Epoch 33/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6216 - loss: 0.6438 - val_accuracy: 0.6132 - val_loss: 0.6853\n",
      "Epoch 34/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6224 - loss: 0.6431 - val_accuracy: 0.5870 - val_loss: 0.6899\n",
      "Epoch 35/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6218 - loss: 0.6428 - val_accuracy: 0.6063 - val_loss: 0.6862\n",
      "Epoch 36/50\n",
      "\u001b[1m10624/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6225 - loss: 0.6423 - val_accuracy: 0.6174 - val_loss: 0.6821\n",
      "Epoch 37/50\n",
      "\u001b[1m10599/10624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6217 - loss: 0.6423"
     ]
    }
   ],
   "source": [
    "\n",
    "class Classifier:\n",
    "    def __init__(self, encoder, input_shape, num_classes):\n",
    "        self.encoder = encoder\n",
    "        self.model = self._build_classifier(input_shape, num_classes)\n",
    "    \n",
    "    def _build_classifier(self, input_shape, num_classes):\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "        # Freeze encoder weights\n",
    "        self.encoder.trainable = False\n",
    "\n",
    "        x = self.encoder(inputs, training=False)  # Use frozen encoder\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        x = layers.Dense(16, activation=\"relu\")(x)\n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        model = models.Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                    loss=\"sparse_categorical_crossentropy\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, batch_size=64, epochs=50, validation_split=0.1):\n",
    "        history = self.model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split)\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        return self.model.evaluate(x_test, y_test)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "# # Load the trained encoder from MaskedAutoencoder\n",
    "# autoencoder = MaskedAutoencoder(input_dim=500)  # Use the correct input dimension\n",
    "\n",
    "# # Define an input layer matching the expected shape\n",
    "# input_layer = layers.Input(shape=(500,))  # Make sure this matches your signal window size\n",
    "\n",
    "# # Pass the input through the autoencoder's encoder\n",
    "# encoded_output = autoencoder.encoder(input_layer)\n",
    "\n",
    "# # Create a new model for the encoder\n",
    "# encoder = models.Model(input_layer, encoded_output)\n",
    "\n",
    "encoder_path = \"encoder_model.keras\"\n",
    "\n",
    "if os.path.exists(encoder_path):\n",
    "    # Load saved encoder\n",
    "    print(\"Loading saved encoder...\")\n",
    "    encoder = tf.keras.models.load_model(encoder_path)\n",
    "else:\n",
    "    # Train autoencoder and extract encoder\n",
    "    autoencoder = MaskedAutoencoder(input_dim=500)\n",
    "    input_layer = layers.Input(shape=(500,))\n",
    "    encoded_output = autoencoder.encoder(input_layer)\n",
    "    encoder = models.Model(input_layer, encoded_output)\n",
    "\n",
    "    # Save encoder\n",
    "    print(\"Saving trained encoder...\")\n",
    "    encoder.save(encoder_path)\n",
    "\n",
    "\n",
    "\n",
    "# Load the target dataset\n",
    "save_dir = os.path.join(univariate_data_path, \"target_univariate.npy\")\n",
    "target_data = np.load(save_dir, allow_pickle=True)\n",
    "\n",
    "# Apply sliding window approach\n",
    "def create_windows(data, window_size=500, step=250):\n",
    "    all_windows, labels = [], []\n",
    "    for sample in data:\n",
    "        signal, label = sample[\"signal\"], sample[\"preterm\"]  # Assuming label is available\n",
    "        for start in range(0, len(signal) - window_size + 1, step):\n",
    "            window = signal[start : start + window_size]\n",
    "            all_windows.append(window)\n",
    "            labels.append(label)\n",
    "    return np.array(all_windows), np.array(labels)\n",
    "\n",
    "x_train, y_train = create_windows(target_data)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "num_classes = len(set(y_train))  # Get number of unique classes\n",
    "classifier = Classifier(encoder, input_shape=(500,), num_classes=num_classes)\n",
    "classifier.train(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Saves in Keras format\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaved encoder!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier.save(\"classifier_model.keras\")  # Saves in Keras format\n",
    "print('Saved encoder!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
