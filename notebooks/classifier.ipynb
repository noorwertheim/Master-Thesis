{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/python3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 12:03:36.900934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741950216.943701  478353 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741950216.956506  478353 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-14 12:03:37.038182: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances: 143\n",
      "Instances with 'preterm' as None: 0\n"
     ]
    }
   ],
   "source": [
    "# print number of instances missing preterm label\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "file_path = os.path.join(processed_data_path, 'target_preprocessed.npy')  # Update this with the actual path\n",
    "target_data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "# Count total instances\n",
    "total_instances = len(target_data)\n",
    "\n",
    "# Count instances where 'preterm' is None\n",
    "none_preterm_count = sum(1 for entry in target_data if entry['preterm'] is None)\n",
    "\n",
    "# Print results\n",
    "print(f\"Total instances: {total_instances}\")\n",
    "print(f\"Instances with 'preterm' as None: {none_preterm_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 12:03:47.053195: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Classifier:\n",
    "    def __init__(self, encoder, input_shape, num_classes):\n",
    "        self.encoder = encoder\n",
    "        self.model = self._build_classifier(input_shape, num_classes)\n",
    "    \n",
    "    def _build_classifier(self, input_shape, num_classes):\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "        # Freeze encoder weights\n",
    "        self.encoder.trainable = False\n",
    "\n",
    "        x = self.encoder(inputs, training=False)  # Use frozen encoder\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        x = layers.Dense(16, activation=\"relu\")(x)\n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        model = models.Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                    loss=\"sparse_categorical_crossentropy\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, batch_size=64, epochs=50, validation_split=0.1):\n",
    "        history = self.model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split)\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        return self.model.evaluate(x_test, y_test)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "# # Load the trained encoder from MaskedAutoencoder\n",
    "# autoencoder = MaskedAutoencoder(input_dim=500)  # Use the correct input dimension\n",
    "\n",
    "# # Define an input layer matching the expected shape\n",
    "# input_layer = layers.Input(shape=(500,))  # Make sure this matches your signal window size\n",
    "\n",
    "# # Pass the input through the autoencoder's encoder\n",
    "# encoded_output = autoencoder.encoder(input_layer)\n",
    "\n",
    "# # Create a new model for the encoder\n",
    "# encoder = models.Model(input_layer, encoded_output)\n",
    "\n",
    "encoder_path = \"../models/encoder_model.keras\"\n",
    "\n",
    "if os.path.exists(encoder_path):\n",
    "    # Load saved encoder\n",
    "    print(\"Loading saved encoder...\")\n",
    "    encoder = tf.keras.models.load_model(encoder_path)\n",
    "else:\n",
    "    # Train autoencoder and extract encoder\n",
    "    autoencoder = MaskedAutoencoder(input_dim=500)\n",
    "    input_layer = layers.Input(shape=(500,))\n",
    "    encoded_output = autoencoder.encoder(input_layer)\n",
    "    encoder = models.Model(input_layer, encoded_output)\n",
    "\n",
    "    # Save encoder\n",
    "    print(\"Saving trained encoder...\")\n",
    "    encoder.save(encoder_path)\n",
    "\n",
    "# Load the target dataset\n",
    "save_dir = os.path.join(univariate_data_path, \"target_univariate.npy\")\n",
    "target_data = np.load(save_dir, allow_pickle=True)\n",
    "\n",
    "def create_windows(data, window_size=500, step=250):\n",
    "    all_windows, labels = [], []\n",
    "    for sample in data:\n",
    "        signal, label = sample[\"signal\"], sample[\"preterm\"]\n",
    "        \n",
    "        # Ensure the label is a valid integer\n",
    "        if label is None:  # Skip instances with None labels (just in case)\n",
    "            continue\n",
    "        \n",
    "        for start in range(0, len(signal) - window_size + 1, step):\n",
    "            window = signal[start : start + window_size]\n",
    "            all_windows.append(window)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(all_windows, dtype=np.float32), np.array(labels, dtype=np.int32)\n",
    "\n",
    "x_train, y_train = create_windows(target_data)  # Make sure this function is called!\n",
    "\n",
    "\n",
    "# print(type(y_train[0]))\n",
    "# # Initialize and train the classifier\n",
    "num_classes = len(set(y_train))  # Get number of unique classes\n",
    "# classifier = Classifier(encoder, input_shape=(500,), num_classes=num_classes)\n",
    "# print(f\"x_train type: {type(x_train)}, dtype: {x_train.dtype}, shape: {x_train.shape}\")\n",
    "# print(f\"y_train type: {type(y_train)}, dtype: {y_train.dtype}, shape: {y_train.shape}\")\n",
    "\n",
    "# classifier.train(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Learning Rate=0.002453, Batch Size=16\n",
      "Epoch 1/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5409 - val_accuracy: 0.7075 - val_loss: 0.6421\n",
      "Epoch 2/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5193 - val_accuracy: 0.7133 - val_loss: 0.6553\n",
      "Epoch 3/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5179 - val_accuracy: 0.7098 - val_loss: 0.6458\n",
      "Epoch 4/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5182 - val_accuracy: 0.7134 - val_loss: 0.6389\n",
      "Epoch 5/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5185 - val_accuracy: 0.7129 - val_loss: 0.6532\n",
      "Epoch 6/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5176 - val_accuracy: 0.7130 - val_loss: 0.6504\n",
      "Epoch 7/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7460 - loss: 0.5166 - val_accuracy: 0.7125 - val_loss: 0.6410\n",
      "Epoch 8/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5150 - val_accuracy: 0.7139 - val_loss: 0.6507\n",
      "Epoch 9/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7471 - loss: 0.5136 - val_accuracy: 0.7144 - val_loss: 0.6453\n",
      "Epoch 10/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5140 - val_accuracy: 0.7131 - val_loss: 0.6605\n",
      "Epoch 11/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5132 - val_accuracy: 0.7136 - val_loss: 0.6457\n",
      "Epoch 12/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5120 - val_accuracy: 0.7131 - val_loss: 0.6397\n",
      "Epoch 13/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.5127 - val_accuracy: 0.7128 - val_loss: 0.6572\n",
      "Epoch 14/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5114 - val_accuracy: 0.7130 - val_loss: 0.6328\n",
      "Epoch 15/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5130 - val_accuracy: 0.7134 - val_loss: 0.6506\n",
      "Epoch 16/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5110 - val_accuracy: 0.7126 - val_loss: 0.6511\n",
      "Epoch 17/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5120 - val_accuracy: 0.7140 - val_loss: 0.6551\n",
      "Epoch 18/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5113 - val_accuracy: 0.7136 - val_loss: 0.6545\n",
      "Epoch 19/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5111 - val_accuracy: 0.7128 - val_loss: 0.6551\n",
      "Epoch 20/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7475 - loss: 0.5105 - val_accuracy: 0.7141 - val_loss: 0.6529\n",
      "Validation Loss: 0.652860\n",
      "\n",
      "Testing: Learning Rate=0.002183, Batch Size=64\n",
      "Epoch 1/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.5426 - val_accuracy: 0.7121 - val_loss: 0.6342\n",
      "Epoch 2/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7446 - loss: 0.5186 - val_accuracy: 0.7105 - val_loss: 0.6143\n",
      "Epoch 3/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5154 - val_accuracy: 0.7131 - val_loss: 0.6357\n",
      "Epoch 4/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7448 - loss: 0.5146 - val_accuracy: 0.7116 - val_loss: 0.6312\n",
      "Epoch 5/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5130 - val_accuracy: 0.7134 - val_loss: 0.6352\n",
      "Epoch 6/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7460 - loss: 0.5123 - val_accuracy: 0.7146 - val_loss: 0.6328\n",
      "Epoch 7/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5113 - val_accuracy: 0.7132 - val_loss: 0.6347\n",
      "Epoch 8/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7470 - loss: 0.5109 - val_accuracy: 0.7149 - val_loss: 0.6349\n",
      "Epoch 9/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5121 - val_accuracy: 0.7148 - val_loss: 0.6364\n",
      "Epoch 10/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5110 - val_accuracy: 0.7148 - val_loss: 0.6396\n",
      "Epoch 11/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5093 - val_accuracy: 0.7155 - val_loss: 0.6248\n",
      "Epoch 12/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7470 - loss: 0.5104 - val_accuracy: 0.7141 - val_loss: 0.6447\n",
      "Epoch 13/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5080 - val_accuracy: 0.7157 - val_loss: 0.6262\n",
      "Epoch 14/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5098 - val_accuracy: 0.7140 - val_loss: 0.6440\n",
      "Epoch 15/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5097 - val_accuracy: 0.7158 - val_loss: 0.6436\n",
      "Epoch 16/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5082 - val_accuracy: 0.7153 - val_loss: 0.6485\n",
      "Epoch 17/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5075 - val_accuracy: 0.7159 - val_loss: 0.6529\n",
      "Epoch 18/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5069 - val_accuracy: 0.7152 - val_loss: 0.6359\n",
      "Epoch 19/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5072 - val_accuracy: 0.7161 - val_loss: 0.6492\n",
      "Epoch 20/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.5067 - val_accuracy: 0.7143 - val_loss: 0.6587\n",
      "Validation Loss: 0.658731\n",
      "\n",
      "Testing: Learning Rate=0.000218, Batch Size=16\n",
      "Epoch 1/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7300 - loss: 0.5822 - val_accuracy: 0.7150 - val_loss: 0.6406\n",
      "Epoch 2/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5255 - val_accuracy: 0.7149 - val_loss: 0.6412\n",
      "Epoch 3/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.5234 - val_accuracy: 0.7150 - val_loss: 0.6375\n",
      "Epoch 4/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5190 - val_accuracy: 0.7110 - val_loss: 0.6360\n",
      "Epoch 5/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7447 - loss: 0.5160 - val_accuracy: 0.7112 - val_loss: 0.6259\n",
      "Epoch 6/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5121 - val_accuracy: 0.7132 - val_loss: 0.6364\n",
      "Epoch 7/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5106 - val_accuracy: 0.7135 - val_loss: 0.6311\n",
      "Epoch 8/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5093 - val_accuracy: 0.7139 - val_loss: 0.6256\n",
      "Epoch 9/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7478 - loss: 0.5073 - val_accuracy: 0.7149 - val_loss: 0.6407\n",
      "Epoch 10/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5073 - val_accuracy: 0.7151 - val_loss: 0.6436\n",
      "Epoch 11/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5068 - val_accuracy: 0.7163 - val_loss: 0.6406\n",
      "Epoch 12/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5063 - val_accuracy: 0.7151 - val_loss: 0.6477\n",
      "Epoch 13/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.5057 - val_accuracy: 0.7159 - val_loss: 0.6519\n",
      "Epoch 14/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5041 - val_accuracy: 0.7164 - val_loss: 0.6464\n",
      "Epoch 15/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5037 - val_accuracy: 0.7164 - val_loss: 0.6557\n",
      "Epoch 16/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5027 - val_accuracy: 0.7164 - val_loss: 0.6485\n",
      "Epoch 17/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7485 - loss: 0.5014 - val_accuracy: 0.7163 - val_loss: 0.6596\n",
      "Epoch 18/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7477 - loss: 0.5021 - val_accuracy: 0.7167 - val_loss: 0.6558\n",
      "Epoch 19/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7500 - loss: 0.4997 - val_accuracy: 0.7152 - val_loss: 0.6543\n",
      "Epoch 20/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5024 - val_accuracy: 0.7163 - val_loss: 0.6656\n",
      "Validation Loss: 0.665558\n",
      "\n",
      "Testing: Learning Rate=0.000239, Batch Size=32\n",
      "Epoch 1/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.7254 - loss: 0.5847 - val_accuracy: 0.7127 - val_loss: 0.6342\n",
      "Epoch 2/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.5234 - val_accuracy: 0.7129 - val_loss: 0.6382\n",
      "Epoch 3/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7454 - loss: 0.5174 - val_accuracy: 0.7127 - val_loss: 0.6392\n",
      "Epoch 4/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5150 - val_accuracy: 0.7136 - val_loss: 0.6361\n",
      "Epoch 5/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5133 - val_accuracy: 0.7129 - val_loss: 0.6353\n",
      "Epoch 6/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7470 - loss: 0.5114 - val_accuracy: 0.7135 - val_loss: 0.6323\n",
      "Epoch 7/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5102 - val_accuracy: 0.7129 - val_loss: 0.6363\n",
      "Epoch 8/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5090 - val_accuracy: 0.7128 - val_loss: 0.6442\n",
      "Epoch 9/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5098 - val_accuracy: 0.7106 - val_loss: 0.6394\n",
      "Epoch 10/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.5069 - val_accuracy: 0.7120 - val_loss: 0.6415\n",
      "Epoch 11/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5075 - val_accuracy: 0.7116 - val_loss: 0.6513\n",
      "Epoch 12/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5065 - val_accuracy: 0.7121 - val_loss: 0.6486\n",
      "Epoch 13/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5055 - val_accuracy: 0.7115 - val_loss: 0.6467\n",
      "Epoch 14/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5044 - val_accuracy: 0.7116 - val_loss: 0.6447\n",
      "Epoch 15/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7479 - loss: 0.5035 - val_accuracy: 0.7115 - val_loss: 0.6387\n",
      "Epoch 16/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7473 - loss: 0.5045 - val_accuracy: 0.7109 - val_loss: 0.6397\n",
      "Epoch 17/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7478 - loss: 0.5032 - val_accuracy: 0.7083 - val_loss: 0.6510\n",
      "Epoch 18/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5020 - val_accuracy: 0.7104 - val_loss: 0.6490\n",
      "Epoch 19/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.5022 - val_accuracy: 0.7095 - val_loss: 0.6496\n",
      "Epoch 20/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7486 - loss: 0.5015 - val_accuracy: 0.7127 - val_loss: 0.6495\n",
      "Validation Loss: 0.649459\n",
      "\n",
      "Testing: Learning Rate=0.000027, Batch Size=64\n",
      "Epoch 1/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.7232 - loss: 0.9905 - val_accuracy: 0.7003 - val_loss: 0.6374\n",
      "Epoch 2/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7351 - loss: 0.5618 - val_accuracy: 0.7020 - val_loss: 0.6377\n",
      "Epoch 3/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.5514 - val_accuracy: 0.7055 - val_loss: 0.6379\n",
      "Epoch 4/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5447 - val_accuracy: 0.7028 - val_loss: 0.6472\n",
      "Epoch 5/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5411 - val_accuracy: 0.7061 - val_loss: 0.6435\n",
      "Epoch 6/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5397 - val_accuracy: 0.7096 - val_loss: 0.6419\n",
      "Epoch 7/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5376 - val_accuracy: 0.7045 - val_loss: 0.6499\n",
      "Epoch 8/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.5383 - val_accuracy: 0.7102 - val_loss: 0.6427\n",
      "Epoch 9/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5379 - val_accuracy: 0.7121 - val_loss: 0.6399\n",
      "Epoch 10/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5361 - val_accuracy: 0.7103 - val_loss: 0.6427\n",
      "Epoch 11/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5357 - val_accuracy: 0.7114 - val_loss: 0.6414\n",
      "Epoch 12/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5353 - val_accuracy: 0.7111 - val_loss: 0.6429\n",
      "Epoch 13/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5348 - val_accuracy: 0.7071 - val_loss: 0.6467\n",
      "Epoch 14/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7371 - loss: 0.5360 - val_accuracy: 0.7127 - val_loss: 0.6422\n",
      "Epoch 15/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5348 - val_accuracy: 0.7127 - val_loss: 0.6406\n",
      "Epoch 16/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5336 - val_accuracy: 0.7114 - val_loss: 0.6419\n",
      "Epoch 17/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5329 - val_accuracy: 0.7125 - val_loss: 0.6411\n",
      "Epoch 18/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5325 - val_accuracy: 0.7140 - val_loss: 0.6360\n",
      "Epoch 19/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5330 - val_accuracy: 0.7142 - val_loss: 0.6358\n",
      "Epoch 20/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5334 - val_accuracy: 0.7093 - val_loss: 0.6481\n",
      "Validation Loss: 0.648143\n",
      "\n",
      "Testing: Learning Rate=0.000015, Batch Size=64\n",
      "Epoch 1/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.7156 - loss: 0.6639 - val_accuracy: 0.6907 - val_loss: 0.6386\n",
      "Epoch 2/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.5683 - val_accuracy: 0.6940 - val_loss: 0.6480\n",
      "Epoch 3/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7339 - loss: 0.5532 - val_accuracy: 0.7058 - val_loss: 0.6401\n",
      "Epoch 4/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7358 - loss: 0.5472 - val_accuracy: 0.7038 - val_loss: 0.6453\n",
      "Epoch 5/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5424 - val_accuracy: 0.7064 - val_loss: 0.6453\n",
      "Epoch 6/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7364 - loss: 0.5410 - val_accuracy: 0.7092 - val_loss: 0.6436\n",
      "Epoch 7/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5377 - val_accuracy: 0.7118 - val_loss: 0.6410\n",
      "Epoch 8/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5370 - val_accuracy: 0.7110 - val_loss: 0.6436\n",
      "Epoch 9/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5358 - val_accuracy: 0.7120 - val_loss: 0.6426\n",
      "Epoch 10/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5355 - val_accuracy: 0.7098 - val_loss: 0.6487\n",
      "Epoch 11/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.5356 - val_accuracy: 0.7112 - val_loss: 0.6450\n",
      "Epoch 12/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5342 - val_accuracy: 0.7109 - val_loss: 0.6474\n",
      "Epoch 13/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5342 - val_accuracy: 0.7128 - val_loss: 0.6426\n",
      "Epoch 14/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5345 - val_accuracy: 0.7121 - val_loss: 0.6438\n",
      "Epoch 15/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7390 - loss: 0.5324 - val_accuracy: 0.7120 - val_loss: 0.6457\n",
      "Epoch 16/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5336 - val_accuracy: 0.7101 - val_loss: 0.6468\n",
      "Epoch 17/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5326 - val_accuracy: 0.7144 - val_loss: 0.6369\n",
      "Epoch 18/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.5321 - val_accuracy: 0.7122 - val_loss: 0.6451\n",
      "Epoch 19/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5324 - val_accuracy: 0.7139 - val_loss: 0.6398\n",
      "Epoch 20/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5323 - val_accuracy: 0.7126 - val_loss: 0.6422\n",
      "Validation Loss: 0.642206\n",
      "\n",
      "Testing: Learning Rate=0.006541, Batch Size=16\n",
      "Epoch 1/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.7412 - loss: 0.5348 - val_accuracy: 0.7096 - val_loss: 0.6416\n",
      "Epoch 2/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7450 - loss: 0.5225 - val_accuracy: 0.7120 - val_loss: 0.6375\n",
      "Epoch 3/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7474 - loss: 0.5191 - val_accuracy: 0.7135 - val_loss: 0.6573\n",
      "Epoch 4/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5194 - val_accuracy: 0.7141 - val_loss: 0.6495\n",
      "Epoch 5/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7457 - loss: 0.5191 - val_accuracy: 0.7123 - val_loss: 0.6382\n",
      "Epoch 6/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5194 - val_accuracy: 0.7129 - val_loss: 0.6489\n",
      "Epoch 7/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5174 - val_accuracy: 0.7138 - val_loss: 0.6659\n",
      "Epoch 8/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.5147 - val_accuracy: 0.7114 - val_loss: 0.6654\n",
      "Epoch 9/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5170 - val_accuracy: 0.7143 - val_loss: 0.6518\n",
      "Epoch 10/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5158 - val_accuracy: 0.7127 - val_loss: 0.6538\n",
      "Epoch 11/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7470 - loss: 0.5163 - val_accuracy: 0.7140 - val_loss: 0.6683\n",
      "Epoch 12/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5152 - val_accuracy: 0.7138 - val_loss: 0.6603\n",
      "Epoch 13/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5157 - val_accuracy: 0.7141 - val_loss: 0.6487\n",
      "Epoch 14/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5171 - val_accuracy: 0.7135 - val_loss: 0.6344\n",
      "Epoch 15/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5157 - val_accuracy: 0.7145 - val_loss: 0.6652\n",
      "Epoch 16/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5158 - val_accuracy: 0.7143 - val_loss: 0.6473\n",
      "Epoch 17/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5157 - val_accuracy: 0.7127 - val_loss: 0.6615\n",
      "Epoch 18/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5160 - val_accuracy: 0.7143 - val_loss: 0.6439\n",
      "Epoch 19/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5161 - val_accuracy: 0.7140 - val_loss: 0.6560\n",
      "Epoch 20/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7473 - loss: 0.5146 - val_accuracy: 0.7145 - val_loss: 0.6451\n",
      "Validation Loss: 0.645099\n",
      "\n",
      "Testing: Learning Rate=0.009476, Batch Size=64\n",
      "Epoch 1/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.7402 - loss: 0.5385 - val_accuracy: 0.7145 - val_loss: 0.6494\n",
      "Epoch 2/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5211 - val_accuracy: 0.7102 - val_loss: 0.6409\n",
      "Epoch 3/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5201 - val_accuracy: 0.7128 - val_loss: 0.6399\n",
      "Epoch 4/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5174 - val_accuracy: 0.7147 - val_loss: 0.6466\n",
      "Epoch 5/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5174 - val_accuracy: 0.7121 - val_loss: 0.6551\n",
      "Epoch 6/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5172 - val_accuracy: 0.7118 - val_loss: 0.6410\n",
      "Epoch 7/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5155 - val_accuracy: 0.7138 - val_loss: 0.6401\n",
      "Epoch 8/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5150 - val_accuracy: 0.7151 - val_loss: 0.6312\n",
      "Epoch 9/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5154 - val_accuracy: 0.7147 - val_loss: 0.6427\n",
      "Epoch 10/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5166 - val_accuracy: 0.7145 - val_loss: 0.6545\n",
      "Epoch 11/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7457 - loss: 0.5164 - val_accuracy: 0.7143 - val_loss: 0.6554\n",
      "Epoch 12/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7454 - loss: 0.5161 - val_accuracy: 0.7154 - val_loss: 0.6490\n",
      "Epoch 13/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7457 - loss: 0.5150 - val_accuracy: 0.7140 - val_loss: 0.6501\n",
      "Epoch 14/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7471 - loss: 0.5154 - val_accuracy: 0.7136 - val_loss: 0.6484\n",
      "Epoch 15/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5146 - val_accuracy: 0.7132 - val_loss: 0.6560\n",
      "Epoch 16/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7457 - loss: 0.5153 - val_accuracy: 0.7129 - val_loss: 0.6527\n",
      "Epoch 17/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5148 - val_accuracy: 0.7161 - val_loss: 0.6513\n",
      "Epoch 18/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5142 - val_accuracy: 0.7163 - val_loss: 0.6480\n",
      "Epoch 19/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5144 - val_accuracy: 0.7138 - val_loss: 0.6619\n",
      "Epoch 20/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7451 - loss: 0.5149 - val_accuracy: 0.7152 - val_loss: 0.6513\n",
      "Validation Loss: 0.651277\n",
      "\n",
      "Testing: Learning Rate=0.000684, Batch Size=16\n",
      "Epoch 1/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.5503 - val_accuracy: 0.7135 - val_loss: 0.6507\n",
      "Epoch 2/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5168 - val_accuracy: 0.7137 - val_loss: 0.6494\n",
      "Epoch 3/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5150 - val_accuracy: 0.7133 - val_loss: 0.6409\n",
      "Epoch 4/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5122 - val_accuracy: 0.7136 - val_loss: 0.6404\n",
      "Epoch 5/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5109 - val_accuracy: 0.7142 - val_loss: 0.6384\n",
      "Epoch 6/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5085 - val_accuracy: 0.7149 - val_loss: 0.6396\n",
      "Epoch 7/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5083 - val_accuracy: 0.7132 - val_loss: 0.6362\n",
      "Epoch 8/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7457 - loss: 0.5082 - val_accuracy: 0.7149 - val_loss: 0.6273\n",
      "Epoch 9/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5065 - val_accuracy: 0.7159 - val_loss: 0.6379\n",
      "Epoch 10/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7474 - loss: 0.5049 - val_accuracy: 0.7161 - val_loss: 0.6389\n",
      "Epoch 11/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7473 - loss: 0.5050 - val_accuracy: 0.7153 - val_loss: 0.6421\n",
      "Epoch 12/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7479 - loss: 0.5041 - val_accuracy: 0.7162 - val_loss: 0.6372\n",
      "Epoch 13/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5046 - val_accuracy: 0.7161 - val_loss: 0.6368\n",
      "Epoch 14/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5024 - val_accuracy: 0.7162 - val_loss: 0.6433\n",
      "Epoch 15/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7470 - loss: 0.5029 - val_accuracy: 0.7162 - val_loss: 0.6509\n",
      "Epoch 16/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7482 - loss: 0.5019 - val_accuracy: 0.7168 - val_loss: 0.6505\n",
      "Epoch 17/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7485 - loss: 0.5010 - val_accuracy: 0.7159 - val_loss: 0.6469\n",
      "Epoch 18/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.5015 - val_accuracy: 0.7162 - val_loss: 0.6477\n",
      "Epoch 19/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7495 - loss: 0.5002 - val_accuracy: 0.7169 - val_loss: 0.6613\n",
      "Epoch 20/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.7487 - loss: 0.5005 - val_accuracy: 0.7175 - val_loss: 0.6497\n",
      "Validation Loss: 0.649721\n",
      "\n",
      "Testing: Learning Rate=0.000012, Batch Size=64\n",
      "Epoch 1/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.7312 - loss: 0.7632 - val_accuracy: 0.6969 - val_loss: 0.6439\n",
      "Epoch 2/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.5656 - val_accuracy: 0.7080 - val_loss: 0.6470\n",
      "Epoch 3/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.5496 - val_accuracy: 0.7103 - val_loss: 0.6464\n",
      "Epoch 4/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7370 - loss: 0.5446 - val_accuracy: 0.7104 - val_loss: 0.6461\n",
      "Epoch 5/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5422 - val_accuracy: 0.7117 - val_loss: 0.6459\n",
      "Epoch 6/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5427 - val_accuracy: 0.7118 - val_loss: 0.6450\n",
      "Epoch 7/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5389 - val_accuracy: 0.7115 - val_loss: 0.6452\n",
      "Epoch 8/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5387 - val_accuracy: 0.7127 - val_loss: 0.6430\n",
      "Epoch 9/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5393 - val_accuracy: 0.7132 - val_loss: 0.6428\n",
      "Epoch 10/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7370 - loss: 0.5387 - val_accuracy: 0.7132 - val_loss: 0.6430\n",
      "Epoch 11/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5372 - val_accuracy: 0.7133 - val_loss: 0.6423\n",
      "Epoch 12/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5363 - val_accuracy: 0.7131 - val_loss: 0.6437\n",
      "Epoch 13/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5358 - val_accuracy: 0.7138 - val_loss: 0.6414\n",
      "Epoch 14/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5359 - val_accuracy: 0.7136 - val_loss: 0.6436\n",
      "Epoch 15/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5360 - val_accuracy: 0.7136 - val_loss: 0.6431\n",
      "Epoch 16/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.5343 - val_accuracy: 0.7139 - val_loss: 0.6415\n",
      "Epoch 17/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5345 - val_accuracy: 0.7137 - val_loss: 0.6421\n",
      "Epoch 18/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5350 - val_accuracy: 0.7139 - val_loss: 0.6430\n",
      "Epoch 19/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5341 - val_accuracy: 0.7141 - val_loss: 0.6417\n",
      "Epoch 20/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5337 - val_accuracy: 0.7130 - val_loss: 0.6447\n",
      "Validation Loss: 0.644723\n",
      "\n",
      "Testing: Learning Rate=0.000074, Batch Size=128\n",
      "Epoch 1/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7183 - loss: 0.6291 - val_accuracy: 0.7108 - val_loss: 0.6283\n",
      "Epoch 2/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7364 - loss: 0.5457 - val_accuracy: 0.7079 - val_loss: 0.6442\n",
      "Epoch 3/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5386 - val_accuracy: 0.7087 - val_loss: 0.6464\n",
      "Epoch 4/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5351 - val_accuracy: 0.7085 - val_loss: 0.6452\n",
      "Epoch 5/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5339 - val_accuracy: 0.7127 - val_loss: 0.6410\n",
      "Epoch 6/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5316 - val_accuracy: 0.7131 - val_loss: 0.6425\n",
      "Epoch 7/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5295 - val_accuracy: 0.7148 - val_loss: 0.6336\n",
      "Epoch 8/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5298 - val_accuracy: 0.7129 - val_loss: 0.6414\n",
      "Epoch 9/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5275 - val_accuracy: 0.7090 - val_loss: 0.6437\n",
      "Epoch 10/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5267 - val_accuracy: 0.7114 - val_loss: 0.6479\n",
      "Epoch 11/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5272 - val_accuracy: 0.7145 - val_loss: 0.6335\n",
      "Epoch 12/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5270 - val_accuracy: 0.7141 - val_loss: 0.6385\n",
      "Epoch 13/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7386 - loss: 0.5241 - val_accuracy: 0.7144 - val_loss: 0.6379\n",
      "Epoch 14/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5234 - val_accuracy: 0.7133 - val_loss: 0.6424\n",
      "Epoch 15/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5235 - val_accuracy: 0.7143 - val_loss: 0.6376\n",
      "Epoch 16/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5229 - val_accuracy: 0.7100 - val_loss: 0.6463\n",
      "Epoch 17/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5223 - val_accuracy: 0.7131 - val_loss: 0.6412\n",
      "Epoch 18/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5232 - val_accuracy: 0.7133 - val_loss: 0.6387\n",
      "Epoch 19/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5227 - val_accuracy: 0.7146 - val_loss: 0.6373\n",
      "Epoch 20/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5211 - val_accuracy: 0.7137 - val_loss: 0.6403\n",
      "Validation Loss: 0.640319\n",
      "\n",
      "Testing: Learning Rate=0.000046, Batch Size=128\n",
      "Epoch 1/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7037 - loss: 0.6884 - val_accuracy: 0.6868 - val_loss: 0.6554\n",
      "Epoch 2/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7340 - loss: 0.5576 - val_accuracy: 0.6955 - val_loss: 0.6500\n",
      "Epoch 3/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7355 - loss: 0.5476 - val_accuracy: 0.6921 - val_loss: 0.6536\n",
      "Epoch 4/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7345 - loss: 0.5443 - val_accuracy: 0.7070 - val_loss: 0.6451\n",
      "Epoch 5/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5406 - val_accuracy: 0.6997 - val_loss: 0.6514\n",
      "Epoch 6/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.5398 - val_accuracy: 0.7066 - val_loss: 0.6423\n",
      "Epoch 7/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5375 - val_accuracy: 0.7061 - val_loss: 0.6464\n",
      "Epoch 8/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7370 - loss: 0.5366 - val_accuracy: 0.7052 - val_loss: 0.6482\n",
      "Epoch 9/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5364 - val_accuracy: 0.7043 - val_loss: 0.6533\n",
      "Epoch 10/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5355 - val_accuracy: 0.7061 - val_loss: 0.6498\n",
      "Epoch 11/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7359 - loss: 0.5366 - val_accuracy: 0.7064 - val_loss: 0.6501\n",
      "Epoch 12/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7370 - loss: 0.5342 - val_accuracy: 0.7058 - val_loss: 0.6507\n",
      "Epoch 13/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7357 - loss: 0.5355 - val_accuracy: 0.7093 - val_loss: 0.6441\n",
      "Epoch 14/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5320 - val_accuracy: 0.6945 - val_loss: 0.6575\n",
      "Epoch 15/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5329 - val_accuracy: 0.7103 - val_loss: 0.6441\n",
      "Epoch 16/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.5327 - val_accuracy: 0.7108 - val_loss: 0.6445\n",
      "Epoch 17/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5313 - val_accuracy: 0.7124 - val_loss: 0.6408\n",
      "Epoch 18/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5304 - val_accuracy: 0.7104 - val_loss: 0.6438\n",
      "Epoch 19/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5301 - val_accuracy: 0.7089 - val_loss: 0.6443\n",
      "Epoch 20/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5293 - val_accuracy: 0.7096 - val_loss: 0.6448\n",
      "Validation Loss: 0.644753\n",
      "\n",
      "Testing: Learning Rate=0.000146, Batch Size=64\n",
      "Epoch 1/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.7201 - loss: 0.5946 - val_accuracy: 0.7063 - val_loss: 0.6462\n",
      "Epoch 2/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5405 - val_accuracy: 0.7130 - val_loss: 0.6392\n",
      "Epoch 3/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5354 - val_accuracy: 0.7123 - val_loss: 0.6417\n",
      "Epoch 4/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5310 - val_accuracy: 0.7130 - val_loss: 0.6403\n",
      "Epoch 5/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5276 - val_accuracy: 0.7135 - val_loss: 0.6309\n",
      "Epoch 6/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.5232 - val_accuracy: 0.7105 - val_loss: 0.6355\n",
      "Epoch 7/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.5215 - val_accuracy: 0.7106 - val_loss: 0.6290\n",
      "Epoch 8/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7442 - loss: 0.5186 - val_accuracy: 0.7092 - val_loss: 0.6383\n",
      "Epoch 9/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5165 - val_accuracy: 0.7106 - val_loss: 0.6285\n",
      "Epoch 10/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7448 - loss: 0.5166 - val_accuracy: 0.7094 - val_loss: 0.6374\n",
      "Epoch 11/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.5166 - val_accuracy: 0.7129 - val_loss: 0.6261\n",
      "Epoch 12/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.5135 - val_accuracy: 0.7115 - val_loss: 0.6272\n",
      "Epoch 13/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5139 - val_accuracy: 0.7100 - val_loss: 0.6373\n",
      "Epoch 14/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5139 - val_accuracy: 0.7120 - val_loss: 0.6259\n",
      "Epoch 15/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5142 - val_accuracy: 0.7126 - val_loss: 0.6242\n",
      "Epoch 16/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.5127 - val_accuracy: 0.7116 - val_loss: 0.6299\n",
      "Epoch 17/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5122 - val_accuracy: 0.7075 - val_loss: 0.6354\n",
      "Epoch 18/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5123 - val_accuracy: 0.7114 - val_loss: 0.6314\n",
      "Epoch 19/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5118 - val_accuracy: 0.7123 - val_loss: 0.6299\n",
      "Epoch 20/20\n",
      "\u001b[1m8562/8562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.7473 - loss: 0.5097 - val_accuracy: 0.7112 - val_loss: 0.6302\n",
      "Validation Loss: 0.630172\n",
      "\n",
      "Testing: Learning Rate=0.000280, Batch Size=128\n",
      "Epoch 1/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7316 - loss: 0.5809 - val_accuracy: 0.7056 - val_loss: 0.6435\n",
      "Epoch 2/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5375 - val_accuracy: 0.7098 - val_loss: 0.6428\n",
      "Epoch 3/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.5303 - val_accuracy: 0.7058 - val_loss: 0.6485\n",
      "Epoch 4/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5258 - val_accuracy: 0.7120 - val_loss: 0.6431\n",
      "Epoch 5/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5232 - val_accuracy: 0.7131 - val_loss: 0.6412\n",
      "Epoch 6/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5210 - val_accuracy: 0.7125 - val_loss: 0.6347\n",
      "Epoch 7/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5190 - val_accuracy: 0.7123 - val_loss: 0.6368\n",
      "Epoch 8/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.5164 - val_accuracy: 0.7109 - val_loss: 0.6331\n",
      "Epoch 9/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7445 - loss: 0.5142 - val_accuracy: 0.7085 - val_loss: 0.6455\n",
      "Epoch 10/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7454 - loss: 0.5129 - val_accuracy: 0.7045 - val_loss: 0.6479\n",
      "Epoch 11/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5119 - val_accuracy: 0.7119 - val_loss: 0.6332\n",
      "Epoch 12/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5096 - val_accuracy: 0.7124 - val_loss: 0.6392\n",
      "Epoch 13/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5096 - val_accuracy: 0.7127 - val_loss: 0.6311\n",
      "Epoch 14/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5096 - val_accuracy: 0.7115 - val_loss: 0.6424\n",
      "Epoch 15/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5078 - val_accuracy: 0.7114 - val_loss: 0.6553\n",
      "Epoch 16/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5079 - val_accuracy: 0.7123 - val_loss: 0.6541\n",
      "Epoch 17/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7475 - loss: 0.5068 - val_accuracy: 0.7121 - val_loss: 0.6493\n",
      "Epoch 18/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5071 - val_accuracy: 0.7125 - val_loss: 0.6447\n",
      "Epoch 19/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5064 - val_accuracy: 0.7124 - val_loss: 0.6433\n",
      "Epoch 20/20\n",
      "\u001b[1m4281/4281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7477 - loss: 0.5048 - val_accuracy: 0.7101 - val_loss: 0.6452\n",
      "Validation Loss: 0.645157\n",
      "\n",
      "Testing: Learning Rate=0.009974, Batch Size=32\n",
      "Epoch 1/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5408 - val_accuracy: 0.7151 - val_loss: 0.6553\n",
      "Epoch 2/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.5330 - val_accuracy: 0.7151 - val_loss: 0.6425\n",
      "Epoch 3/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5334 - val_accuracy: 0.7151 - val_loss: 0.6474\n",
      "Epoch 4/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7386 - loss: 0.5325 - val_accuracy: 0.7151 - val_loss: 0.6475\n",
      "Epoch 5/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5321 - val_accuracy: 0.7151 - val_loss: 0.6477\n",
      "Epoch 6/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5331 - val_accuracy: 0.7151 - val_loss: 0.6463\n",
      "Epoch 7/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5319 - val_accuracy: 0.7151 - val_loss: 0.6404\n",
      "Epoch 8/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5330 - val_accuracy: 0.7151 - val_loss: 0.6429\n",
      "Epoch 9/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7390 - loss: 0.5320 - val_accuracy: 0.7151 - val_loss: 0.6335\n",
      "Epoch 10/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5321 - val_accuracy: 0.7151 - val_loss: 0.6512\n",
      "Epoch 11/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5320 - val_accuracy: 0.7151 - val_loss: 0.6561\n",
      "Epoch 12/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5321 - val_accuracy: 0.7151 - val_loss: 0.6442\n",
      "Epoch 13/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.5323 - val_accuracy: 0.7151 - val_loss: 0.6385\n",
      "Epoch 14/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7386 - loss: 0.5320 - val_accuracy: 0.7151 - val_loss: 0.6325\n",
      "Epoch 15/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.5317 - val_accuracy: 0.7151 - val_loss: 0.6435\n",
      "Epoch 16/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7390 - loss: 0.5313 - val_accuracy: 0.7151 - val_loss: 0.6517\n",
      "Epoch 17/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5321 - val_accuracy: 0.7151 - val_loss: 0.6390\n",
      "Epoch 18/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.5314 - val_accuracy: 0.7151 - val_loss: 0.6448\n",
      "Epoch 19/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5320 - val_accuracy: 0.7151 - val_loss: 0.6419\n",
      "Epoch 20/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5329 - val_accuracy: 0.7151 - val_loss: 0.6503\n",
      "Validation Loss: 0.650251\n",
      "\n",
      "Testing: Learning Rate=0.000010, Batch Size=32\n",
      "Epoch 1/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.6433 - loss: 0.8519 - val_accuracy: 0.7009 - val_loss: 0.6327\n",
      "Epoch 2/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.5643 - val_accuracy: 0.7043 - val_loss: 0.6336\n",
      "Epoch 3/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5511 - val_accuracy: 0.7080 - val_loss: 0.6347\n",
      "Epoch 4/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5444 - val_accuracy: 0.7082 - val_loss: 0.6401\n",
      "Epoch 5/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5423 - val_accuracy: 0.7093 - val_loss: 0.6410\n",
      "Epoch 6/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5410 - val_accuracy: 0.7096 - val_loss: 0.6418\n",
      "Epoch 7/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5391 - val_accuracy: 0.7100 - val_loss: 0.6427\n",
      "Epoch 8/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5373 - val_accuracy: 0.7109 - val_loss: 0.6412\n",
      "Epoch 9/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7382 - loss: 0.5361 - val_accuracy: 0.7109 - val_loss: 0.6413\n",
      "Epoch 10/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5371 - val_accuracy: 0.7119 - val_loss: 0.6405\n",
      "Epoch 11/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5349 - val_accuracy: 0.7124 - val_loss: 0.6391\n",
      "Epoch 12/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5354 - val_accuracy: 0.7116 - val_loss: 0.6417\n",
      "Epoch 13/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5353 - val_accuracy: 0.7124 - val_loss: 0.6402\n",
      "Epoch 14/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5343 - val_accuracy: 0.7126 - val_loss: 0.6396\n",
      "Epoch 15/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5355 - val_accuracy: 0.7118 - val_loss: 0.6417\n",
      "Epoch 16/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5339 - val_accuracy: 0.7128 - val_loss: 0.6420\n",
      "Epoch 17/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5325 - val_accuracy: 0.7104 - val_loss: 0.6438\n",
      "Epoch 18/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5324 - val_accuracy: 0.7099 - val_loss: 0.6425\n",
      "Epoch 19/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5318 - val_accuracy: 0.7114 - val_loss: 0.6423\n",
      "Epoch 20/20\n",
      "\u001b[1m17124/17124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.7371 - loss: 0.5324 - val_accuracy: 0.7139 - val_loss: 0.6348\n",
      "Validation Loss: 0.634827\n",
      "\n",
      "Testing: Learning Rate=0.000010, Batch Size=16\n",
      "Epoch 1/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.6531 - loss: 0.8131 - val_accuracy: 0.6771 - val_loss: 0.6631\n",
      "Epoch 2/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.5614 - val_accuracy: 0.7012 - val_loss: 0.6476\n",
      "Epoch 3/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5503 - val_accuracy: 0.7041 - val_loss: 0.6506\n",
      "Epoch 4/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 0.5435 - val_accuracy: 0.7104 - val_loss: 0.6499\n",
      "Epoch 5/20\n",
      "\u001b[1m34247/34247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.7382 - loss: 0.5387 - val_accuracy: 0.7130 - val_loss: 0.6490\n",
      "Epoch 6/20\n",
      "\u001b[1m18124/34247\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 933us/step - accuracy: 0.7377 - loss: 0.5386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_val_loss\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Print best hyperparameters\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/skopt/optimizer/gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/skopt/optimizer/base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[1;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/skopt/utils.py:779\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    776\u001b[0m arg_dict \u001b[38;5;241m=\u001b[39m {dim\u001b[38;5;241m.\u001b[39mname: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m classifier\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Return final validation loss (minimization objective)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m final_val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mClassifier.train\u001b[0;34m(self, x_train, y_train, batch_size, epochs, validation_split)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:222\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[1;32m    226\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/data/ops/optional_ops.py:194\u001b[0m, in \u001b[0;36m_OptionalImpl.get_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m   result \u001b[38;5;241m=\u001b[39m gen_optional_ops\u001b[38;5;241m.\u001b[39moptional_get_value(\n\u001b[1;32m    187\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[1;32m    188\u001b[0m       name\u001b[38;5;241m=\u001b[39mscope,\n\u001b[1;32m    189\u001b[0m       output_types\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_types(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec),\n\u001b[1;32m    190\u001b[0m       output_shapes\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_shapes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec),\n\u001b[1;32m    191\u001b[0m   )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# NOTE: We do not colocate the deserialization of composite tensors\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# because not all ops are guaranteed to have non-GPU kernels.\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:274\u001b[0m, in \u001b[0;36mfrom_tensor_list\u001b[0;34m(element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an element constructed from the given spec and tensor list.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    spec is not compatible with the tensor list.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_tensor_list_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:229\u001b[0m, in \u001b[0;36m_from_tensor_list_helper\u001b[0;34m(decode_fn, element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    227\u001b[0m   flat_ret\u001b[38;5;241m.\u001b[39mappend(decode_fn(component_spec, value))\n\u001b[1;32m    228\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_flat_values\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_ret\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/data/util/nest.py:87\u001b[0m, in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpack_sequence_as\u001b[39m(structure, flat_sequence):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a given flattened sequence packed into a nest.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m  If `structure` is a scalar, `flat_sequence` must be a single-element list;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    ValueError: If nest and structure have different element counts.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     89\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:859\u001b[0m, in \u001b[0;36mpack_sequence_as\u001b[0;34m(modality, structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m    856\u001b[0m       structure, flat_sequence, expand_composites, sequence_fn\n\u001b[1;32m    857\u001b[0m   )\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[0;32m--> 859\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_data_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    862\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown modality used \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for nested structure\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(modality)\n\u001b[1;32m    863\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:963\u001b[0m, in \u001b[0;36m_tf_data_pack_sequence_as\u001b[0;34m(structure, flat_sequence)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flat_structure) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(flat_sequence):\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    957\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not pack sequence. Argument `structure` had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    958\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(flat_structure)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, but argument `flat_sequence` had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(flat_sequence)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements. Received structure: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, flat_sequence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflat_sequence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    961\u001b[0m   )\n\u001b[0;32m--> 963\u001b[0m _, packed \u001b[38;5;241m=\u001b[39m \u001b[43m_tf_data_packed_nest_with_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sequence_like(structure, packed)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:604\u001b[0m, in \u001b[0;36m_tf_data_packed_nest_with_indices\u001b[0;34m(structure, flat, index)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function for pack_nest_as.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    (assuming indexing starts from `index`).\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m packed \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 604\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_tf_data_yield_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_tf_data_is_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_tf_data_packed_nest_with_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:387\u001b[0m, in \u001b[0;36m_tf_data_yield_value\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yield elements of `iterable` in a deterministic order.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m  The iterable elements in a deterministic order.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iterable, _collections_abc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    388\u001b[0m   \u001b[38;5;66;03m# Iterate through dictionaries in a deterministic order by sorting the\u001b[39;00m\n\u001b[1;32m    389\u001b[0m   \u001b[38;5;66;03m# keys. Notice this means that we ignore the original order of `OrderedDict`\u001b[39;00m\n\u001b[1;32m    390\u001b[0m   \u001b[38;5;66;03m# instances. This is intentional, to avoid potential bugs caused by mixing\u001b[39;00m\n\u001b[1;32m    391\u001b[0m   \u001b[38;5;66;03m# ordered and plain dicts (e.g., flattening a dict but using a\u001b[39;00m\n\u001b[1;32m    392\u001b[0m   \u001b[38;5;66;03m# corresponding `OrderedDict` to pack it back).\u001b[39;00m\n\u001b[1;32m    393\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _tf_data_sorted(iterable):\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m iterable[key]\n",
      "File \u001b[0;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define search space: learning rate (log-uniform) & batch size (powers of 2)\n",
    "search_space = [\n",
    "    Real(1e-5, 1e-2, \"log-uniform\", name=\"learning_rate\"),  # Learning rate\n",
    "    Categorical([16, 32, 64, 128], name=\"batch_size\")  # Only powers of 2\n",
    "]\n",
    "\n",
    "# Objective function for optimization\n",
    "@use_named_args(search_space)\n",
    "def objective(learning_rate, batch_size):\n",
    "    print(f\"Testing: Learning Rate={learning_rate:.6f}, Batch Size={batch_size}\")\n",
    "\n",
    "    # Create classifier with frozen encoder\n",
    "    classifier = Classifier(encoder, input_shape=(500,), num_classes=num_classes)\n",
    "\n",
    "    # Compile with the given learning rate\n",
    "    classifier.model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = classifier.train(x_train, y_train, batch_size=batch_size, epochs=20, validation_split=0.1)\n",
    "\n",
    "    # Return final validation loss (minimization objective)\n",
    "    final_val_loss = history.history[\"val_loss\"][-1]\n",
    "    print(f\"Validation Loss: {final_val_loss:.6f}\\n\")\n",
    "\n",
    "    return final_val_loss\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "result = gp_minimize(objective, search_space, n_calls=30, random_state=42)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Learning Rate: {result.x[0]:.6f}\")\n",
    "print(f\"Batch Size: {result.x[1]}\")\n",
    "\n",
    "# Plot optimization results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(result.func_vals)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Bayesian Optimization Progress\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier model saved at: ../models/classifier_model.keras\n"
     ]
    }
   ],
   "source": [
    "# Define save path\n",
    "classifier_save_path = \"../models/classifier_model.keras\"\n",
    "\n",
    "# Save the trained classifier\n",
    "classifier.model.save(classifier_save_path)\n",
    "\n",
    "print(f\"Classifier model saved at: {classifier_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
