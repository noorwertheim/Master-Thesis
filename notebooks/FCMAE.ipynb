{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nwertheim/miniconda3/bin/python\n",
      "/home/nwertheim/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import matplotlib.pyplot as plt\n",
    "from FCMAE_model import FCMAE, ConvNeXtBlock1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "num_epochs = 5\n",
    "num_blocks = 5\n",
    "kernel_size = 9\n",
    "base_dim = 128\n",
    "learning_rate = 3.57844559759971e-05\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4003,)\n",
      "(1171,)\n",
      "(33060, 1)\n",
      "{'record_name': 'icehg956-chan0', 'signal': array([[ 3.15242801],\n",
      "       [ 2.93295337],\n",
      "       [ 2.72134811],\n",
      "       ...,\n",
      "       [-0.50079448],\n",
      "       [-0.52595218],\n",
      "       [-0.54716481]]), 'metadata': {'fs': 20, 'sig_len': 35460, 'n_sig': 6, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'sig_name': ['S1', 'S1_DOCFILT-4-0.08-5', 'S2', 'S2_DOCFILT-4-0.08-5', 'S3', 'S3_DOCFILT-4-0.08-5'], 'comments': ['Comments:', 'RecID 956', 'RecType Induced', 'Gestation 40', 'Rectime 30.3', 'Age 28', 'Weight 82', 'Placental_position end', 'Height 173', 'Newborn_weight 3350', 'Pair_RecID 958']}}\n"
     ]
    }
   ],
   "source": [
    "train_file = os.path.join(univariate_data_path, 'merged_univariate_no_PCA_train.npy')\n",
    "train_data = np.load(train_file, allow_pickle=True)\n",
    "test_file = os.path.join(univariate_data_path, 'merged_univariate_no_PCA_test.npy')\n",
    "test_data = np.load(test_file, allow_pickle=True)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "print(train_data[0]['signal'].shape)\n",
    "print(train_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9669, 12000)\n",
      "(3179, 12000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create time windows from the signal data\n",
    "def create_time_windows(data, window_length=12000, step_size=12000):\n",
    "    \"\"\"\n",
    "    Create sliding windows of a specified length and step size from a list of signals.\n",
    "\n",
    "    Args:\n",
    "        data: list of dicts, each containing a 'signal' array of shape (seq_len, 1)\n",
    "        window_length: number of time steps in each window\n",
    "        step_size: number of time steps to move between windows (for overlap)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (num_windows, window_length), univariate windows\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "\n",
    "    for entry in data:\n",
    "        signal = entry['signal'].flatten()  # shape: (seq_len,)\n",
    "        signal_length = len(signal)\n",
    "\n",
    "        if signal_length < window_length:\n",
    "            continue\n",
    "\n",
    "        for start_idx in range(0, signal_length - window_length + 1, step_size):\n",
    "            end_idx = start_idx + window_length\n",
    "            window = signal[start_idx:end_idx]\n",
    "            windows.append(window)\n",
    "\n",
    "    return np.array(windows)  # shape: (num_windows, window_length)\n",
    "\n",
    "\n",
    "X_train = create_time_windows(train_data)\n",
    "X_test = create_time_windows(test_data)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def split_data(windows, test_size=0.1, val_size=0.1, random_seed=42):\n",
    "#     \"\"\"\n",
    "#     Splits the dataset into training, validation, and test sets with specified proportions.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - windows (numpy.ndarray): The dataset to split, shaped as (num_samples, window_size).\n",
    "#     - test_size (float): Proportion of data to be used for the test set.\n",
    "#     - val_size (float): Proportion of data to be used for the validation set.\n",
    "#     - random_seed (int): Seed for reproducibility.\n",
    "\n",
    "#     Returns:\n",
    "#     - X_train, X_val, X_test: The splits of the dataset.\n",
    "#     \"\"\"\n",
    "#     # First, split into train and temp (test + validation)\n",
    "#     X_train, X_temp = train_test_split(windows, test_size=(test_size + val_size), random_state=random_seed)\n",
    "    \n",
    "#     # Then, split the temp into validation and test\n",
    "#     val_size_adjusted = val_size / (val_size + test_size)  # Adjust to split remaining temp\n",
    "#     X_val, X_test = train_test_split(X_temp, test_size=val_size_adjusted, random_state=random_seed)\n",
    "    \n",
    "#     return X_train, X_val, X_test\n",
    "\n",
    "# # Example usage with your windows data\n",
    "# X_train, X_val, X_test = split_data(windows, test_size=0.1, val_size=0.1)\n",
    "\n",
    "# # Check the shapes of the splits\n",
    "# print(f\"Training set shape: {X_train.shape}\")\n",
    "# print(f\"Validation set shape: {X_val.shape}\")\n",
    "# print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Training set shape: (9669, 12000)\n",
      "Masked Test set shape: (3179, 12000)\n"
     ]
    }
   ],
   "source": [
    "def mask_data(x, mask_ratio=0.5, patch_size=8):\n",
    "    \"\"\"\n",
    "    Apply patch-based masking to a batch of univariate time series.\n",
    "\n",
    "    Args:\n",
    "        x: np.ndarray of shape (num_windows, window_length)\n",
    "        mask_ratio: float, fraction of patches to mask\n",
    "        patch_size: int, number of time steps in each patch\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: masked version of x with same shape\n",
    "    \"\"\"\n",
    "    x_masked = np.copy(x)\n",
    "    num_windows, window_length = x.shape\n",
    "    num_patches = window_length // patch_size\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        mask = np.random.rand(num_patches) < mask_ratio\n",
    "        for j in range(num_patches):\n",
    "            if mask[j]:\n",
    "                start = j * patch_size\n",
    "                end = (j + 1) * patch_size\n",
    "                x_masked[i, start:end] = 0  # or np.nan if you prefer\n",
    "\n",
    "    return x_masked\n",
    "\n",
    "# Apply masking to train, validation, and test sets\n",
    "mask_ratio = 0.75  # Adjust this to your desired masking ratio\n",
    "masked_X_train = mask_data(X_train, mask_ratio)\n",
    "masked_X_test = mask_data(X_test, mask_ratio)\n",
    "\n",
    "# Check the shape of the masked datasets\n",
    "print(f\"Masked Training set shape: {masked_X_train.shape}\")\n",
    "print(f\"Masked Test set shape: {masked_X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_masked_examples(original, masked, num_examples=5):\n",
    "#     plt.figure(figsize=(15, num_examples * 2.5))\n",
    "    \n",
    "#     for i in range(num_examples):\n",
    "#         # Original signal\n",
    "#         plt.subplot(num_examples, 2, 2*i + 1)\n",
    "#         plt.plot(original[i], color='blue')\n",
    "#         plt.title(f\"Original Signal {i+1}\")\n",
    "#         plt.xlabel(\"Time step\")\n",
    "#         plt.ylabel(\"Amplitude\")\n",
    "\n",
    "#         # Masked signal\n",
    "#         plt.subplot(num_examples, 2, 2*i + 2)\n",
    "#         plt.plot(masked[i], color='orange')\n",
    "#         plt.title(f\"Masked Signal {i+1}\")\n",
    "#         plt.xlabel(\"Time step\")\n",
    "#         plt.ylabel(\"Amplitude\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# plot_masked_examples(windows, masked_windows, num_examples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked shape torch.Size([3179, 1, 12000])\n",
      "unmasked shape torch.Size([3179, 1, 12000])\n",
      "train shapes torch.Size([9669, 1, 12000]) torch.Size([9669, 1, 12000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FCMAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv1d(1, 128, kernel_size=(9,), stride=(2,), padding=(4,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(128, 256, kernel_size=(9,), stride=(2,), padding=(4,))\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose1d(256, 256, kernel_size=(9,), stride=(2,), padding=(4,), output_padding=(1,))\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose1d(256, 128, kernel_size=(9,), stride=(2,), padding=(4,), output_padding=(1,))\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (output_layer): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define batch size\n",
    "batch_size = batch_size\n",
    "\n",
    "# Convert to tensors (still on CPU at this point)\n",
    "masked_X_train_tensor = torch.tensor(masked_X_train, dtype=torch.float32).unsqueeze(1)\n",
    "unmasked_X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "masked_X_test_tensor = torch.tensor(masked_X_test, dtype=torch.float32).unsqueeze(1)\n",
    "unmasked_X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "print('masked shape', masked_X_test_tensor.shape)\n",
    "print('unmasked shape', unmasked_X_test_tensor.shape)\n",
    "# Create TensorDatasets with both masked and unmasked tensors\n",
    "train_dataset = TensorDataset(masked_X_train_tensor, unmasked_X_train_tensor)\n",
    "test_dataset = TensorDataset(masked_X_test_tensor, unmasked_X_test_tensor)\n",
    "print('train shapes', masked_X_train_tensor.shape, unmasked_X_train_tensor.shape)\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Define model\n",
    "model = FCMAE(in_channels=1, base_dim=base_dim, num_blocks=num_blocks, kernel_size=kernel_size)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0133\n",
      "Epoch [1/5], Train Loss: 0.2248\n",
      "Test Loss: 0.1996\n",
      "Epoch [2/5], Train Loss: 0.1972\n",
      "Test Loss: 0.1951\n",
      "Epoch [3/5], Train Loss: 0.1940\n",
      "Test Loss: 0.1910\n",
      "Epoch [4/5], Train Loss: 0.1917\n",
      "Test Loss: 0.1906\n",
      "Epoch [5/5], Train Loss: 0.1900\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Lists to store train and test losses for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Testing loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for masked_input, original_input in test_loader:\n",
    "            # Send data to device (GPU/CPU)\n",
    "            masked_input = masked_input.to(device)\n",
    "            original_input = original_input.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            reconstructed = model(masked_input)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(reconstructed, original_input)\n",
    "\n",
    "            # Update test loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        # Calculate average test loss for this epoch\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "    \n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for masked_input, original_input in train_loader:\n",
    "        # Send data to device (GPU/CPU)\n",
    "        masked_input = masked_input.to(device)\n",
    "        original_input = original_input.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        reconstructed = model(masked_input)\n",
    "\n",
    "        # Compute loss (compare reconstructed to the original unmasked input)\n",
    "        loss = criterion(reconstructed, original_input)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average train loss for this epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    \n",
    "\n",
    "# Plotting after training\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label=\"Test Loss\", marker='x')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train and Test Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m batch_input = batch[\u001b[32m0\u001b[39m].to(device)  \u001b[38;5;66;03m# Move batch to the device (GPU or CPU)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Get the reconstruction from the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Take the first test sample (index 0)\u001b[39;00m\n\u001b[32m     16\u001b[39m original_sequence = batch_input[\u001b[32m0\u001b[39m].cpu().numpy().flatten()  \u001b[38;5;66;03m# Flatten for easier plotting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home3/nwertheim/Master-Thesis/notebooks/FCMAE_model.py:75\u001b[39m, in \u001b[36mFCMAE.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.decoder(x)\n\u001b[32m     77\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.output_layer(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the model to evaluation mode (no gradient tracking)\n",
    "model.eval()\n",
    "\n",
    "# Choose a test sample (here, we take the first sample from the test_loader)\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    # Get a batch from the test loader\n",
    "    for batch in test_loader:\n",
    "        batch_input = batch[0].to(device)  # Move batch to the device (GPU or CPU)\n",
    "        \n",
    "        # Get the reconstruction from the model\n",
    "        output = model(batch_input)\n",
    "\n",
    "        # Take the first test sample (index 0)\n",
    "        original_sequence = batch_input[0].cpu().numpy().flatten()  # Flatten for easier plotting\n",
    "        reconstructed_sequence = output[0].cpu().numpy().flatten()\n",
    "\n",
    "        # Plotting the original and reconstructed sequence\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(original_sequence, label=\"Original Sequence\")\n",
    "        plt.plot(reconstructed_sequence, label=\"Reconstructed Sequence\", linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.title(\"Original vs Reconstructed Sequence (Test Sample)\")\n",
    "        plt.xlabel(\"Time Step\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.show()\n",
    "\n",
    "        break  # Only plot for the first test batch (you can modify this if you want to loop through more samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/nwertheim.11575130/ipykernel_245241/740407544.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m masked_input = masked.to(device)  \u001b[38;5;66;03m# Move batch to the device (GPU or CPU)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Get the reconstruction from the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Take the first test sample (index 0)\u001b[39;00m\n\u001b[32m     24\u001b[39m masked_sequence = masked_input[\u001b[32m0\u001b[39m].cpu().numpy().flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home3/nwertheim/Master-Thesis/notebooks/FCMAE_model.py:75\u001b[39m, in \u001b[36mFCMAE.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.decoder(x)\n\u001b[32m     77\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.output_layer(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "# '''Plotting example reconstruction'''\n",
    "# import matplotlib.pyplot as plt\n",
    "# path = os.path.join(models_path, 'FCMAE_best_multiple_encoder_cpu.pth')\n",
    "\n",
    "# # Load the full FCMAE model\n",
    "# model = FCMAE(in_channels=1, base_dim=128, num_blocks=5, kernel_size=9)\n",
    "\n",
    "\n",
    "# # Load the saved weights into the full model\n",
    "# state_dict = torch.load(path)\n",
    "# model.load_state_dict(state_dict)\n",
    "# # Set the model to evaluation mode (no gradient tracking)\n",
    "# model.eval()\n",
    "\n",
    "# # Choose a test sample (here, we take the first sample from the test_loader)\n",
    "# with torch.no_grad():  # Disable gradient calculation for inference\n",
    "#     # Get a batch from the test loader\n",
    "#     for masked, original in test_loader:\n",
    "#         masked_input = masked.to(device)  # Move batch to the device (GPU or CPU)\n",
    "#         # Get the reconstruction from the model\n",
    "#         output = model(masked_input)\n",
    "\n",
    "#         # Take the first test sample (index 0)\n",
    "#         masked_sequence = masked_input[0].cpu().numpy().flatten()\n",
    "#         reconstructed_sequence = output[0].cpu().numpy().flatten()\n",
    "#         original_sequence = original[0].numpy().flatten()\n",
    "\n",
    "#         # Create one figure with two subplots\n",
    "#         fig, axs = plt.subplots(2, 1, figsize=(12, 10))  # 3 rows, 1 column\n",
    "\n",
    "\n",
    "#         # Plot the original sequence\n",
    "#         axs[0].plot(masked_sequence, label=\"Masked Sequence\", color='blue')\n",
    "#         axs[0].set_title(\"Masked Sequence\")\n",
    "#         axs[0].set_xlabel(\"Time Step\")\n",
    "#         axs[0].set_ylabel(\"Amplitude\")\n",
    "#         axs[0].legend()\n",
    "\n",
    "#         # Plot the original sequence\n",
    "#         axs[1].plot(original_sequence, label=\"Original Sequence\", color='blue')\n",
    "#         axs[1].set_title(\"Original Sequence\")\n",
    "#         axs[1].set_xlabel(\"Time Step\")\n",
    "#         axs[1].set_ylabel(\"Amplitude\")\n",
    "#         axs[1].legend()\n",
    "\n",
    "#         # Plot the reconstructed sequence\n",
    "#         axs[1].plot(reconstructed_sequence, label=\"Reconstructed Sequence\", linestyle='--', color='pink')\n",
    "#         axs[1].set_title(\"Reconstructed Sequence\")\n",
    "#         axs[1].set_xlabel(\"Time Step\")\n",
    "#         axs[1].set_ylabel(\"Amplitude\")\n",
    "#         axs[1].legend()\n",
    "\n",
    "        \n",
    "\n",
    "#         plt.tight_layout()  # Adjust spacing\n",
    "#         plt.show()\n",
    "\n",
    "#         break  # Only plot for the first test batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# path = os.path.join(models_path, 'FCMAE_best_multiple_encoder_cpu.pth')\n",
    "\n",
    "# # Load the full FCMAE model\n",
    "# model = FCMAE(in_channels=1, base_dim=128, num_blocks=5, kernel_size=9)\n",
    "\n",
    "\n",
    "# # Load the saved weights into the full model\n",
    "# state_dict = torch.load(path)\n",
    "# model.load_state_dict(state_dict)\n",
    "# # Set the model to evaluation mode (no gradient tracking)\n",
    "# model.eval()\n",
    "\n",
    "# # Choose a test sample (here, we take the first sample from the test_loader)\n",
    "# with torch.no_grad():  # Disable gradient calculation for inference\n",
    "#     # Get a batch from the test loader\n",
    "#     for batch in test_loader:\n",
    "#         batch_input = batch[0].to(device)  # Move batch to the device (GPU or CPU)\n",
    "        \n",
    "#         # Get the reconstruction from the model\n",
    "#         output = model(batch_input)\n",
    "\n",
    "#         # Take the first test sample (index 0)\n",
    "#         masked_sequence = batch_input[0].cpu().numpy().flatten()\n",
    "#         reconstructed_sequence = output[0].cpu().numpy().flatten()\n",
    "\n",
    "#         # Create one figure with two subplots\n",
    "#         fig, axs = plt.subplots(2, 1, figsize=(12, 8))  # 2 rows, 1 column\n",
    "\n",
    "#         # Plot the original sequence\n",
    "#         axs[0].plot(masked_sequence, label=\"Masked Sequence\")\n",
    "#         axs[0].set_title(\"Masked Sequence\")\n",
    "#         axs[0].set_xlabel(\"Time Step\")\n",
    "#         axs[0].set_ylabel(\"Amplitude\")\n",
    "#         axs[0].legend()\n",
    "\n",
    "#         # Plot the reconstructed sequence\n",
    "#         axs[1].plot(reconstructed_sequence, label=\"Reconstructed Sequence\", linestyle='--', color='orange')\n",
    "#         axs[1].set_title(\"Reconstructed Sequence\")\n",
    "#         axs[1].set_xlabel(\"Time Step\")\n",
    "#         axs[1].set_ylabel(\"Amplitude\")\n",
    "#         axs[1].legend()\n",
    "\n",
    "#         plt.tight_layout()  # Adjust spacing\n",
    "#         plt.show()\n",
    "\n",
    "#         break  # Only plot for the first test batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the path where you want to save the encoder\n",
    "# path = os.path.join(models_path, 'FCMAE_encoder_cpu_final.pth')\n",
    "\n",
    "# # Save the encoder part of the model\n",
    "# torch.save(model.state_dict(), path)\n",
    "\n",
    "# print(f\"Model encoder saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
