{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666,)\n"
     ]
    }
   ],
   "source": [
    "data_file = os.path.join(univariate_data_path, 'merged_univariate.npy')\n",
    "data = np.load(data_file, allow_pickle=True)\n",
    "print(data.shape)\n",
    "\n",
    "# Check for NaN or Inf values in signals\n",
    "for sample in data:\n",
    "    if np.isnan(sample['signal']).any() or np.isinf(sample['signal']).any():\n",
    "        print(f\"NaN or Inf detected in {sample['record_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454061, 500)\n"
     ]
    }
   ],
   "source": [
    "# Function to create sliding windows from a signal\n",
    "def create_windows(sequence, window_size, step_size):\n",
    "    windows = [sequence[i:i+window_size] for i in range(0, len(sequence) - window_size + 1, step_size)]\n",
    "    return np.array(windows)\n",
    "\n",
    "# Set windowing parameters\n",
    "window_size = 500  # Length of each window\n",
    "step_size = 250    # Step size for windowing (overlap)\n",
    "\n",
    "# Process each record and apply windowing\n",
    "all_windows = []\n",
    "\n",
    "for record in data:\n",
    "    signal = record['signal']  # Extract the signal from the record\n",
    "    \n",
    "    # Create windows from the signal\n",
    "    windows = create_windows(signal, window_size, step_size)\n",
    "    all_windows.append(windows)\n",
    "\n",
    "# Convert the list of windows into a numpy array\n",
    "all_windows = np.concatenate(all_windows, axis=0)\n",
    "\n",
    "print(all_windows.shape)  # Should print (num_windows, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454061, 500)\n"
     ]
    }
   ],
   "source": [
    "# Function to mask a percentage of data in each window\n",
    "def mask_data(windows, mask_percentage=0.2):\n",
    "    masked_windows = windows.copy()\n",
    "    num_masked = int(mask_percentage * windows.shape[1])  # Number of values to mask per window\n",
    "    for i in range(windows.shape[0]):\n",
    "        mask_indices = np.random.choice(windows.shape[1], num_masked, replace=False)\n",
    "        masked_windows[i, mask_indices] = np.nan  # Mask with NaN (or 0, depending on choice)\n",
    "    return masked_windows\n",
    "\n",
    "# Mask 20% of data in each window\n",
    "masked_windows = mask_data(all_windows, mask_percentage=0.2)\n",
    "\n",
    "print(masked_windows.shape)  # Should be same as all_windows: (num_windows, window_size)\n",
    "masked_windows = np.nan_to_num(masked_windows, nan=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking masked_windows...\n",
      "NaN values: 0\n",
      "Inf values: 0\n",
      "Checking all_windows...\n",
      "NaN values: 0\n",
      "Inf values: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Checking masked_windows...\")\n",
    "print(\"NaN values:\", np.isnan(masked_windows).sum())\n",
    "print(\"Inf values:\", np.isinf(masked_windows).sum())\n",
    "\n",
    "print(\"Checking all_windows...\")\n",
    "print(\"NaN values:\", np.isnan(all_windows).sum())\n",
    "print(\"Inf values:\", np.isinf(all_windows).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 09:34:02.256396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741768442.275845  681267 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741768442.281829  681267 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 09:34:02.301283: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/nwertheim/.local/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2025-03-12 09:34:05.897626: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 1.4351 - val_loss: 0.8644\n",
      "Epoch 2/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0742 - val_loss: 0.3224\n",
      "Epoch 3/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0448 - val_loss: 0.1944\n",
      "Epoch 4/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0348 - val_loss: 0.1495\n",
      "Epoch 5/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0312 - val_loss: 0.1245\n",
      "Epoch 6/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0290 - val_loss: 0.0984\n",
      "Epoch 7/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0269 - val_loss: 0.0925\n",
      "Epoch 8/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0264 - val_loss: 0.0873\n",
      "Epoch 9/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0246 - val_loss: 0.0827\n",
      "Epoch 10/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0244 - val_loss: 0.0802\n",
      "Epoch 11/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0240 - val_loss: 0.0763\n",
      "Epoch 12/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0725\n",
      "Epoch 13/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0225 - val_loss: 0.0686\n",
      "Epoch 14/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0221 - val_loss: 0.0720\n",
      "Epoch 15/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0219 - val_loss: 0.0607\n",
      "Epoch 16/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0215 - val_loss: 0.0614\n",
      "Epoch 17/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0210 - val_loss: 0.0566\n",
      "Epoch 18/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0210 - val_loss: 0.0595\n",
      "Epoch 19/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0204 - val_loss: 0.0534\n",
      "Epoch 20/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0206 - val_loss: 0.0533\n",
      "Epoch 21/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0204 - val_loss: 0.0506\n",
      "Epoch 22/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0201 - val_loss: 0.0492\n",
      "Epoch 23/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0199 - val_loss: 0.0480\n",
      "Epoch 24/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0450\n",
      "Epoch 25/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0195 - val_loss: 0.0462\n",
      "Epoch 26/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0194 - val_loss: 0.0449\n",
      "Epoch 27/50\n",
      "\u001b[1m6386/6386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0191 - val_loss: 0.0435\n",
      "Epoch 28/50\n",
      "\u001b[1m3432/6386\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.0189"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MaskedAutoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MaskedAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = models.Sequential([\n",
    "            layers.Dense(128),\n",
    "            layers.LeakyReLU(alpha=0.01),\n",
    "            layers.Dense(64),\n",
    "            layers.LeakyReLU(alpha=0.01),\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = models.Sequential([\n",
    "            layers.Dense(128),\n",
    "            layers.LeakyReLU(alpha=0.01),\n",
    "            layers.Dense(input_dim, activation='linear')  # Reconstruct original input\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Set input shape\n",
    "input_dim = 500  # Each window has 500 elements\n",
    "autoencoder = MaskedAutoencoder(input_dim)\n",
    "\n",
    "# Use Adam optimizer with lower learning rate and gradient clipping\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "\n",
    "autoencoder.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Train the model and store history\n",
    "history = autoencoder.fit(masked_windows, all_windows, epochs=50, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Plot loss per epoch\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='dashed')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Autoencoder Training Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# Save the encoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39msave(path)  \u001b[38;5;66;03m# Saves in Keras format\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaved encoder!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "path = os.path.join(models_path, 'encoder_model.keras')\n",
    "autoencoder.encoder.save(path)  # Saves in Keras format\n",
    "print('Saved encoder!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
