{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nwertheim/miniconda3/bin/python\n",
      "/home/nwertheim/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "print(sys.executable)\n",
    "sys.path.insert(1, '../src/')\n",
    "from config import raw_data_path, univariate_data_path, processed_data_path, models_path\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import matplotlib.pyplot as plt\n",
    "from FCMAE_model import FCMAE, ConvNeXtBlock1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532,)\n",
      "(134,)\n",
      "(72200, 1)\n",
      "{'record_name': 'ice002_p_2of3', 'signal': array([[-12.15116958],\n",
      "       [-24.48972151],\n",
      "       [-18.22349939],\n",
      "       ...,\n",
      "       [  3.40956282],\n",
      "       [  1.22642183],\n",
      "       [  4.90008321]]), 'metadata': {'fs': 20, 'sig_len': 746000, 'n_sig': 16, 'base_date': None, 'base_time': None, 'units': ['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'], 'comments': ['Info:', 'ID:ice002', 'Record type:pregnancy', 'Record number:2/3', 'Age(years):38', 'BMI before pregnancy:20.7', 'BMI at recording:25.9', 'Gravidity:4', 'Parity:1', 'Previous caesarean:No', 'Placental position:Posterior', 'Gestational age at recording(w/d):39/1', 'Gestational age at delivery:40/4', 'Mode of delivery:Vaginal', 'Synthetic oxytocin use in labour:No', 'Epidural during labour:No', 'Comments for recording:', 'Reference on right hip - apparent reverse ECG.', 'Comments for delivery:']}}\n"
     ]
    }
   ],
   "source": [
    "train_file = os.path.join(univariate_data_path, 'merged_univariate_train.npy')\n",
    "train_data = np.load(train_file, allow_pickle=True)\n",
    "test_file = os.path.join(univariate_data_path, 'merged_univariate_test.npy')\n",
    "test_data = np.load(test_file, allow_pickle=True)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "print(train_data[0]['signal'].shape)\n",
    "print(train_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 12000)\n",
      "(320, 12000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create time windows from the signal data\n",
    "def create_time_windows(data, window_length=12000, step_size=12000):\n",
    "    \"\"\"\n",
    "    Create sliding windows of a specified length and step size from a list of signals.\n",
    "\n",
    "    Args:\n",
    "        data: list of dicts, each containing a 'signal' array of shape (seq_len, 1)\n",
    "        window_length: number of time steps in each window\n",
    "        step_size: number of time steps to move between windows (for overlap)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (num_windows, window_length), univariate windows\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "\n",
    "    for entry in data:\n",
    "        signal = entry['signal'].flatten()  # shape: (seq_len,)\n",
    "        signal_length = len(signal)\n",
    "\n",
    "        if signal_length < window_length:\n",
    "            continue\n",
    "\n",
    "        for start_idx in range(0, signal_length - window_length + 1, step_size):\n",
    "            end_idx = start_idx + window_length\n",
    "            window = signal[start_idx:end_idx]\n",
    "            windows.append(window)\n",
    "\n",
    "    return np.array(windows)  # shape: (num_windows, window_length)\n",
    "\n",
    "\n",
    "X_train = create_time_windows(train_data)\n",
    "X_test = create_time_windows(test_data)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def split_data(windows, test_size=0.1, val_size=0.1, random_seed=42):\n",
    "#     \"\"\"\n",
    "#     Splits the dataset into training, validation, and test sets with specified proportions.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - windows (numpy.ndarray): The dataset to split, shaped as (num_samples, window_size).\n",
    "#     - test_size (float): Proportion of data to be used for the test set.\n",
    "#     - val_size (float): Proportion of data to be used for the validation set.\n",
    "#     - random_seed (int): Seed for reproducibility.\n",
    "\n",
    "#     Returns:\n",
    "#     - X_train, X_val, X_test: The splits of the dataset.\n",
    "#     \"\"\"\n",
    "#     # First, split into train and temp (test + validation)\n",
    "#     X_train, X_temp = train_test_split(windows, test_size=(test_size + val_size), random_state=random_seed)\n",
    "    \n",
    "#     # Then, split the temp into validation and test\n",
    "#     val_size_adjusted = val_size / (val_size + test_size)  # Adjust to split remaining temp\n",
    "#     X_val, X_test = train_test_split(X_temp, test_size=val_size_adjusted, random_state=random_seed)\n",
    "    \n",
    "#     return X_train, X_val, X_test\n",
    "\n",
    "# # Example usage with your windows data\n",
    "# X_train, X_val, X_test = split_data(windows, test_size=0.1, val_size=0.1)\n",
    "\n",
    "# # Check the shapes of the splits\n",
    "# print(f\"Training set shape: {X_train.shape}\")\n",
    "# print(f\"Validation set shape: {X_val.shape}\")\n",
    "# print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Training set shape: (1230, 12000)\n",
      "Masked Test set shape: (320, 12000)\n"
     ]
    }
   ],
   "source": [
    "def mask_data(x, mask_ratio=0.5, patch_size=8):\n",
    "    \"\"\"\n",
    "    Apply patch-based masking to a batch of univariate time series.\n",
    "\n",
    "    Args:\n",
    "        x: np.ndarray of shape (num_windows, window_length)\n",
    "        mask_ratio: float, fraction of patches to mask\n",
    "        patch_size: int, number of time steps in each patch\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: masked version of x with same shape\n",
    "    \"\"\"\n",
    "    x_masked = np.copy(x)\n",
    "    num_windows, window_length = x.shape\n",
    "    num_patches = window_length // patch_size\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        mask = np.random.rand(num_patches) < mask_ratio\n",
    "        for j in range(num_patches):\n",
    "            if mask[j]:\n",
    "                start = j * patch_size\n",
    "                end = (j + 1) * patch_size\n",
    "                x_masked[i, start:end] = 0  # or np.nan if you prefer\n",
    "\n",
    "    return x_masked\n",
    "\n",
    "# Apply masking to train, validation, and test sets\n",
    "mask_ratio = 0.75  # Adjust this to your desired masking ratio\n",
    "masked_X_train = mask_data(X_train, mask_ratio)\n",
    "masked_X_test = mask_data(X_test, mask_ratio)\n",
    "\n",
    "# Check the shape of the masked datasets\n",
    "print(f\"Masked Training set shape: {masked_X_train.shape}\")\n",
    "print(f\"Masked Test set shape: {masked_X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_masked_examples(original, masked, num_examples=5):\n",
    "#     plt.figure(figsize=(15, num_examples * 2.5))\n",
    "    \n",
    "#     for i in range(num_examples):\n",
    "#         # Original signal\n",
    "#         plt.subplot(num_examples, 2, 2*i + 1)\n",
    "#         plt.plot(original[i], color='blue')\n",
    "#         plt.title(f\"Original Signal {i+1}\")\n",
    "#         plt.xlabel(\"Time step\")\n",
    "#         plt.ylabel(\"Amplitude\")\n",
    "\n",
    "#         # Masked signal\n",
    "#         plt.subplot(num_examples, 2, 2*i + 2)\n",
    "#         plt.plot(masked[i], color='orange')\n",
    "#         plt.title(f\"Masked Signal {i+1}\")\n",
    "#         plt.xlabel(\"Time step\")\n",
    "#         plt.ylabel(\"Amplitude\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# plot_masked_examples(windows, masked_windows, num_examples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwertheim/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-23 15:45:57,221] A new study created in memory with name: no-name-e9d72477-265b-4215-965d-095d6b359e40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:  <optuna.trial._trial.Trial object at 0x14df03380ec0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-23 15:59:03,723] Trial 0 finished with value: 0.0011366075050318614 and parameters: {'num_blocks': 3, 'kernel_size': 3, 'base_dim': 32, 'learning_rate': 0.00016091546580773128, 'batch_size': 32}. Best is trial 0 with value: 0.0011366075050318614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:  <optuna.trial._trial.Trial object at 0x14de532a5880>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Your FCMAE definition here (same as you provided above)\n",
    "# Your ConvNeXtBlock1D if needed\n",
    "\n",
    "# Assume masked_X_train is already a NumPy array\n",
    "masked_X_train_tensor = torch.tensor(masked_X_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 2, 5)\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5, 7, 9])\n",
    "    base_dim = trial.suggest_categorical(\"base_dim\", [32, 64, 128])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_losses = []\n",
    "    print('Trial: ', trial)\n",
    "    for train_index, val_index in kf.split(masked_X_train_tensor):\n",
    "        train_dataset = TensorDataset(masked_X_train_tensor[train_index])\n",
    "        val_dataset = TensorDataset(masked_X_train_tensor[val_index])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = FCMAE(in_channels=1, base_dim=base_dim, num_blocks=num_blocks, kernel_size=kernel_size).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Train for a few epochs (keep low for speed)\n",
    "        for epoch in range(5):\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                inputs = batch[0].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate on validation fold\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch[0].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        fold_losses.append(avg_val_loss)\n",
    "\n",
    "    return np.mean(fold_losses)\n",
    "\n",
    "# Start Optuna tuning\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n",
    "path = os.path.join(models_path, 'fcmae_cv_optuna.pkl')\n",
    "\n",
    "# Optionally save the study for later\n",
    "import joblib\n",
    "joblib.dump(study, path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
